{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cubic-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchsummary\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from sklearn.metrics import f1_score, fbeta_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "296249af-6756-48b5-ad2b-f30d942632c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/opt/ml/input/data/train'\n",
    "\n",
    "data_info = pd.read_csv(train_dir + '/train.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c764cb7-8212-4c61-831e-6ab406f6137b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>45</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>52</td>\n",
       "      <td>000002_female_Asian_52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000004</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>54</td>\n",
       "      <td>000004_male_Asian_54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000005</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>58</td>\n",
       "      <td>000005_female_Asian_58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000006</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>59</td>\n",
       "      <td>000006_female_Asian_59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  gender   race  age                    path\n",
       "0  000001  female  Asian   45  000001_female_Asian_45\n",
       "1  000002  female  Asian   52  000002_female_Asian_52\n",
       "2  000004    male  Asian   54    000004_male_Asian_54\n",
       "3  000005  female  Asian   58  000005_female_Asian_58\n",
       "4  000006  female  Asian   59  000006_female_Asian_59"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0572c10a-acee-4648-9ad8-cf97e07a9992",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = ['/incorrect_mask.jpg', '/mask1.jpg','/mask2.jpg','/mask3.jpg','/mask4.jpg','/mask5.jpg', '/normal.jpg']\n",
    "\n",
    "prepro_data_info = pd.DataFrame(columns={'id','img_path','race','mask','gender','age','label'})\n",
    "\n",
    "all_id, all_path, all_race, all_mask, all_age, all_gender, all_label = [],[],[],[],[],[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e19e9974-3b8d-403c-b1af-d0bd788b44ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for absolute_path in glob(train_dir + \"/images/*/*\"):\n",
    "    split_list = absolute_path.split(\"/\")\n",
    "    img_name = split_list[-1]\n",
    "    img_path = split_list[-2]\n",
    "    \n",
    "    path_split = img_path.split(\"_\")\n",
    "    \n",
    "    img_id = path_split[0]\n",
    "    img_gender = 0 if path_split[1] == \"male\" else 1\n",
    "    img_race = path_split[2]\n",
    "    img_age = min(2, int(path_split[3]) // 30)\n",
    "    \n",
    "    img_mask = 0\n",
    "    if 'incorrect' in img_name:\n",
    "        img_mask = 1\n",
    "    elif 'normal' in img_name:\n",
    "        img_mask = 2\n",
    "    \n",
    "    all_id.append(img_id)\n",
    "    all_path.append(absolute_path)\n",
    "    all_race.append(img_race)\n",
    "    all_mask.append(img_mask)\n",
    "    all_gender.append(img_gender)\n",
    "    all_age.append(img_age)\n",
    "    all_label.append(img_mask*6 + img_gender*3 + img_age)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6039403-a075-4972-ab6b-d9a1d0c3c9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepro_data_info['id'] = all_id\n",
    "prepro_data_info['img_path'] = all_path\n",
    "prepro_data_info['race'] = all_race\n",
    "prepro_data_info['mask'] = all_mask\n",
    "prepro_data_info['gender'] = all_gender\n",
    "prepro_data_info['age'] = all_age\n",
    "prepro_data_info['label'] = all_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b15d0978-097c-4e2f-b509-eb6bbd7c34f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>label</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>id</th>\n",
       "      <th>mask</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Asian</td>\n",
       "      <td>0</td>\n",
       "      <td>003124</td>\n",
       "      <td>0</td>\n",
       "      <td>/opt/ml/input/data/train/images/003124_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>Asian</td>\n",
       "      <td>0</td>\n",
       "      <td>003124</td>\n",
       "      <td>1</td>\n",
       "      <td>/opt/ml/input/data/train/images/003124_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>Asian</td>\n",
       "      <td>0</td>\n",
       "      <td>003124</td>\n",
       "      <td>2</td>\n",
       "      <td>/opt/ml/input/data/train/images/003124_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Asian</td>\n",
       "      <td>0</td>\n",
       "      <td>003124</td>\n",
       "      <td>0</td>\n",
       "      <td>/opt/ml/input/data/train/images/003124_female_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Asian</td>\n",
       "      <td>0</td>\n",
       "      <td>003124</td>\n",
       "      <td>0</td>\n",
       "      <td>/opt/ml/input/data/train/images/003124_female_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  label   race  age      id  mask  \\\n",
       "0       1      3  Asian    0  003124     0   \n",
       "1       1      9  Asian    0  003124     1   \n",
       "2       1     15  Asian    0  003124     2   \n",
       "3       1      3  Asian    0  003124     0   \n",
       "4       1      3  Asian    0  003124     0   \n",
       "\n",
       "                                            img_path  \n",
       "0  /opt/ml/input/data/train/images/003124_female_...  \n",
       "1  /opt/ml/input/data/train/images/003124_female_...  \n",
       "2  /opt/ml/input/data/train/images/003124_female_...  \n",
       "3  /opt/ml/input/data/train/images/003124_female_...  \n",
       "4  /opt/ml/input/data/train/images/003124_female_...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepro_data_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85a67b3e-2de1-47b6-85ff-62ec99ba8125",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomDataset(Dataset):\n",
    "    def __init__(self, prepro_data_info, train=True):\n",
    "        self.data_info = prepro_data_info # preprocessFunction()\n",
    "\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "\n",
    "        self.image_path = self.data_info.img_path.tolist()\n",
    "        self.label_arr = self.data_info.label.tolist()\n",
    "\n",
    "        self.data_len = len(self.data_info.img_path)\n",
    "        \n",
    "        self.train = train\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_thing = Image.open(self.image_path[index])\n",
    "        \n",
    "        img_thing = img_thing.resize((24, 32))\n",
    "        img_thing = np.asarray(img_thing)/255\n",
    "        \n",
    "        img_tensor = self.to_tensor(img_thing)\n",
    "        \n",
    "        if self.train:\n",
    "            img_label = self.label_arr[index]\n",
    "            return (img_tensor, img_label)\n",
    "        else:\n",
    "            return img_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c91667f-2592-4eaf-88e0-999716c56857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15120, 7) (3780, 7)\n"
     ]
    }
   ],
   "source": [
    "LR = 0.01\n",
    "SEED = 42\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_data, valid_data = train_test_split(prepro_data_info, test_size=0.20, random_state=SEED)\n",
    "\n",
    "print(train_data.shape, valid_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8175f3e-e6e2-49f9-a31c-21d837642a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_custom_dataset = MyCustomDataset(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4224ac59-a53c-4941-bf38-cb68982b1e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, _ = my_custom_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9079ecf9-f91f-41f2-b351-07e187fbd9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 24])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40604a6a-4a6b-4a19-a855-a615dd5a620b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15120"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_custom_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3b65151-0797-48f7-b8fa-c43d07fde964",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MyCustomModel, self).__init__()\n",
    "        \n",
    "        self.cnn1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(16*14*10, 18)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.cnn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4913451-d657-4d76-9f47-0b0bb23a793b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCustomModel(\n",
      "  (cnn1): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu1): ReLU()\n",
      "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=2240, out_features=18, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "my_model = MyCustomModel()\n",
    "my_model.to(device)\n",
    "print(my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5aec7e29-779e-4e24-a544-e02304971dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 28, 20]           1,216\n",
      "              ReLU-2           [-1, 16, 28, 20]               0\n",
      "         MaxPool2d-3           [-1, 16, 14, 10]               0\n",
      "            Linear-4                   [-1, 18]          40,338\n",
      "================================================================\n",
      "Total params: 41,554\n",
      "Trainable params: 41,554\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.15\n",
      "Params size (MB): 0.16\n",
      "Estimated Total Size (MB): 0.32\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(my_model, (3, 32, 24), device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f019e5d-f077-42ed-8364-07aa32f7dcb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eopch: 0 | Batch ID: 0 | Loss: 2.8517744541168213\n",
      "Eopch: 0 | Batch ID: 200 | Loss: 2.2389233112335205\n",
      "Eopch: 0 | Batch ID: 400 | Loss: 1.9165019989013672\n",
      "Eopch: 0 | Batch ID: 600 | Loss: 1.8566482067108154\n",
      "Eopch: 0 | Batch ID: 800 | Loss: 1.7792977094650269\n",
      "Eopch: 0 | Batch ID: 1000 | Loss: 1.6436325311660767\n",
      "Eopch: 1 | Batch ID: 0 | Loss: 1.656982183456421\n",
      "Eopch: 1 | Batch ID: 200 | Loss: 1.4331414699554443\n",
      "Eopch: 1 | Batch ID: 400 | Loss: 1.4985780715942383\n",
      "Eopch: 1 | Batch ID: 600 | Loss: 1.1567212343215942\n",
      "Eopch: 1 | Batch ID: 800 | Loss: 1.1487308740615845\n",
      "Eopch: 1 | Batch ID: 1000 | Loss: 1.226937174797058\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "my_dataset_loader = torch.utils.data.DataLoader(dataset=my_custom_dataset, batch_size=14, shuffle=False)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(my_model.parameters(), lr=LR)\n",
    "\n",
    "for epoch in range(2):\n",
    "    for i, (images, labels) in enumerate(my_dataset_loader):\n",
    "        images = Variable(images).cuda()\n",
    "        labels = Variable(labels).cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = my_model(images.float())\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%200 == 0:\n",
    "            print(f\"Eopch: {epoch} | Batch ID: {i} | Loss: {loss.data}\")\n",
    "\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2ef2f5c-8b94-4ee4-800d-ea2fd2fb829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = MyCustomDataset(valid_data)\n",
    "\n",
    "valid_dataloader = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=14, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "082f4438-9ff4-4a8e-9e95-c0d349b57ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5857142857142857\n",
      "F1 Score: 0.3100556696333911\n"
     ]
    }
   ],
   "source": [
    "targets = []\n",
    "all_predictions = []\n",
    "\n",
    "for images, labels in valid_dataloader:\n",
    "    with torch.no_grad():\n",
    "        images = Variable(images).cuda()\n",
    "        labels = Variable(labels).cuda()\n",
    "        \n",
    "        pred = my_model(images.float())\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        \n",
    "        targets.extend(labels.cpu().numpy())\n",
    "        \n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(targets, all_predictions)}\")\n",
    "print(f\"F1 Score: {np.mean(f1_score(targets, all_predictions, average=None))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eb1e32-f718-4c9d-8afd-17ed569bf549",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
