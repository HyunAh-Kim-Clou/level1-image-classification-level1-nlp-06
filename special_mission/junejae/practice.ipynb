{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cubic-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchsummary\n",
    "\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from sklearn.metrics import f1_score, fbeta_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0d6f2e8-3dfb-4841-acff-10ff4ea91462",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.0001\n",
    "SEED = 42\n",
    "EPOCH = 14\n",
    "BATCH_SIZE = 35\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "train_dir = '/opt/ml/input/data/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0572c10a-acee-4648-9ad8-cf97e07a9992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessedData():\n",
    "    data_info = pd.read_csv(train_dir + '/train.csv', header=0)\n",
    "\n",
    "    prepro_data_info = pd.DataFrame(columns={'id','img_path','race','mask','gender','age','label'})\n",
    "\n",
    "    all_id, all_path, all_race, all_mask, all_age, all_gender, all_label = [],[],[],[],[],[],[]\n",
    "\n",
    "    for absolute_path in glob(train_dir + \"/images/*/*\"):\n",
    "        split_list = absolute_path.split(\"/\")\n",
    "        img_name = split_list[-1]\n",
    "        img_path = split_list[-2]\n",
    "\n",
    "        path_split = img_path.split(\"_\")\n",
    "\n",
    "        img_id = path_split[0]\n",
    "        img_gender = 0 if path_split[1] == \"male\" else 1\n",
    "        img_race = path_split[2]\n",
    "        img_age = min(2, int(path_split[3]) // 30)\n",
    "\n",
    "        img_mask = 0\n",
    "        if 'incorrect' in img_name:\n",
    "            img_mask = 1\n",
    "        elif 'normal' in img_name:\n",
    "            img_mask = 2\n",
    "\n",
    "        all_id.append(img_id)\n",
    "        all_path.append(absolute_path)\n",
    "        all_race.append(img_race)\n",
    "        all_mask.append(img_mask)\n",
    "        all_gender.append(img_gender)\n",
    "        all_age.append(img_age)\n",
    "        all_label.append(img_mask*6 + img_gender*3 + img_age)\n",
    "\n",
    "    prepro_data_info['id'] = all_id\n",
    "    prepro_data_info['img_path'] = all_path\n",
    "    prepro_data_info['race'] = all_race\n",
    "    prepro_data_info['mask'] = all_mask\n",
    "    prepro_data_info['gender'] = all_gender\n",
    "    prepro_data_info['age'] = all_age\n",
    "    prepro_data_info['label'] = all_label\n",
    "    \n",
    "    return prepro_data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85a67b3e-2de1-47b6-85ff-62ec99ba8125",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomDataset(Dataset):\n",
    "    def __init__(self, prepro_data_info, transform, train=True):\n",
    "        self.data_info = prepro_data_info # preprocessFunction()\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.image_path = self.data_info.img_path.tolist()\n",
    "        self.label_arr = self.data_info.label.tolist()\n",
    "\n",
    "        self.data_len = len(self.data_info.img_path)\n",
    "        \n",
    "        self.train = train\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_thing = Image.open(self.image_path[index])\n",
    "        \n",
    "        if self.transform:\n",
    "            img_thing = self.transform(img_thing)\n",
    "        \n",
    "        if self.train:\n",
    "            img_label = self.label_arr[index]\n",
    "            return (img_thing, torch.tensor(img_label))\n",
    "        else:\n",
    "            return img_thing\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c91667f-2592-4eaf-88e0-999716c56857",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MyCustomModel, self).__init__()\n",
    "        \n",
    "        self.resnet18 = models.resnet18(pretrained=True)\n",
    "        \n",
    "        self.resnet18.fc = torch.nn.Linear(in_features=512, out_features=18, bias=True)\n",
    "        \n",
    "        # initialize\n",
    "        nn.init.xavier_uniform_(self.resnet18.fc.weight)\n",
    "        stdv = 1. / math.sqrt(self.resnet18.fc.weight.size(1))\n",
    "        self.resnet18.fc.bias.data.uniform_(-stdv,stdv)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.resnet18(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3b65151-0797-48f7-b8fa-c43d07fde964",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([Resize((512,384),Image.BILINEAR), ToTensor(), Normalize(mean=(0.5,0.5,0.5), std=(0.2,0.2,0.2))])\n",
    "\n",
    "train_data, valid_data = train_test_split(preprocessedData(), test_size=0.2, random_state=SEED)\n",
    "\n",
    "my_custom_dataset = MyCustomDataset(train_data, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4913451-d657-4d76-9f47-0b0bb23a793b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCustomModel(\n",
      "  (resnet18): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=512, out_features=18, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "my_model = MyCustomModel()\n",
    "my_model.to(device)\n",
    "print(my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5aec7e29-779e-4e24-a544-e02304971dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 192]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 256, 192]             128\n",
      "              ReLU-3         [-1, 64, 256, 192]               0\n",
      "         MaxPool2d-4          [-1, 64, 128, 96]               0\n",
      "            Conv2d-5          [-1, 64, 128, 96]          36,864\n",
      "       BatchNorm2d-6          [-1, 64, 128, 96]             128\n",
      "              ReLU-7          [-1, 64, 128, 96]               0\n",
      "            Conv2d-8          [-1, 64, 128, 96]          36,864\n",
      "       BatchNorm2d-9          [-1, 64, 128, 96]             128\n",
      "             ReLU-10          [-1, 64, 128, 96]               0\n",
      "       BasicBlock-11          [-1, 64, 128, 96]               0\n",
      "           Conv2d-12          [-1, 64, 128, 96]          36,864\n",
      "      BatchNorm2d-13          [-1, 64, 128, 96]             128\n",
      "             ReLU-14          [-1, 64, 128, 96]               0\n",
      "           Conv2d-15          [-1, 64, 128, 96]          36,864\n",
      "      BatchNorm2d-16          [-1, 64, 128, 96]             128\n",
      "             ReLU-17          [-1, 64, 128, 96]               0\n",
      "       BasicBlock-18          [-1, 64, 128, 96]               0\n",
      "           Conv2d-19          [-1, 128, 64, 48]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 64, 48]             256\n",
      "             ReLU-21          [-1, 128, 64, 48]               0\n",
      "           Conv2d-22          [-1, 128, 64, 48]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 64, 48]             256\n",
      "           Conv2d-24          [-1, 128, 64, 48]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 64, 48]             256\n",
      "             ReLU-26          [-1, 128, 64, 48]               0\n",
      "       BasicBlock-27          [-1, 128, 64, 48]               0\n",
      "           Conv2d-28          [-1, 128, 64, 48]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 64, 48]             256\n",
      "             ReLU-30          [-1, 128, 64, 48]               0\n",
      "           Conv2d-31          [-1, 128, 64, 48]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 64, 48]             256\n",
      "             ReLU-33          [-1, 128, 64, 48]               0\n",
      "       BasicBlock-34          [-1, 128, 64, 48]               0\n",
      "           Conv2d-35          [-1, 256, 32, 24]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 32, 24]             512\n",
      "             ReLU-37          [-1, 256, 32, 24]               0\n",
      "           Conv2d-38          [-1, 256, 32, 24]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 32, 24]             512\n",
      "           Conv2d-40          [-1, 256, 32, 24]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 32, 24]             512\n",
      "             ReLU-42          [-1, 256, 32, 24]               0\n",
      "       BasicBlock-43          [-1, 256, 32, 24]               0\n",
      "           Conv2d-44          [-1, 256, 32, 24]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 32, 24]             512\n",
      "             ReLU-46          [-1, 256, 32, 24]               0\n",
      "           Conv2d-47          [-1, 256, 32, 24]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 32, 24]             512\n",
      "             ReLU-49          [-1, 256, 32, 24]               0\n",
      "       BasicBlock-50          [-1, 256, 32, 24]               0\n",
      "           Conv2d-51          [-1, 512, 16, 12]       1,179,648\n",
      "      BatchNorm2d-52          [-1, 512, 16, 12]           1,024\n",
      "             ReLU-53          [-1, 512, 16, 12]               0\n",
      "           Conv2d-54          [-1, 512, 16, 12]       2,359,296\n",
      "      BatchNorm2d-55          [-1, 512, 16, 12]           1,024\n",
      "           Conv2d-56          [-1, 512, 16, 12]         131,072\n",
      "      BatchNorm2d-57          [-1, 512, 16, 12]           1,024\n",
      "             ReLU-58          [-1, 512, 16, 12]               0\n",
      "       BasicBlock-59          [-1, 512, 16, 12]               0\n",
      "           Conv2d-60          [-1, 512, 16, 12]       2,359,296\n",
      "      BatchNorm2d-61          [-1, 512, 16, 12]           1,024\n",
      "             ReLU-62          [-1, 512, 16, 12]               0\n",
      "           Conv2d-63          [-1, 512, 16, 12]       2,359,296\n",
      "      BatchNorm2d-64          [-1, 512, 16, 12]           1,024\n",
      "             ReLU-65          [-1, 512, 16, 12]               0\n",
      "       BasicBlock-66          [-1, 512, 16, 12]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                   [-1, 18]           9,234\n",
      "           ResNet-69                   [-1, 18]               0\n",
      "================================================================\n",
      "Total params: 11,185,746\n",
      "Trainable params: 11,185,746\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 2.25\n",
      "Forward/backward pass size (MB): 246.00\n",
      "Params size (MB): 42.67\n",
      "Estimated Total Size (MB): 290.92\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(my_model, (3, 512, 384), device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f019e5d-f077-42ed-8364-07aa32f7dcb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Batch ID: 0 | Loss: 3.920926809310913\n",
      "Epoch: 0 | Batch ID: 100 | Loss: 0.6130409240722656\n",
      "Epoch: 0 | Batch ID: 200 | Loss: 0.31257835030555725\n",
      "Epoch: 0 | Batch ID: 300 | Loss: 0.155760258436203\n",
      "Epoch: 0 | Batch ID: 400 | Loss: 0.13007326424121857\n",
      "Epoch: 1 | Batch ID: 0 | Loss: 0.17924515902996063\n",
      "Epoch: 1 | Batch ID: 100 | Loss: 0.11576660722494125\n",
      "Epoch: 1 | Batch ID: 200 | Loss: 0.03979545459151268\n",
      "Epoch: 1 | Batch ID: 300 | Loss: 0.020044289529323578\n",
      "Epoch: 1 | Batch ID: 400 | Loss: 0.01719667762517929\n",
      "Epoch: 2 | Batch ID: 0 | Loss: 0.012813077308237553\n",
      "Epoch: 2 | Batch ID: 100 | Loss: 0.018772300332784653\n",
      "Epoch: 2 | Batch ID: 200 | Loss: 0.02035280503332615\n",
      "Epoch: 2 | Batch ID: 300 | Loss: 0.00940747931599617\n",
      "Epoch: 2 | Batch ID: 400 | Loss: 0.010171102359890938\n",
      "Epoch: 3 | Batch ID: 0 | Loss: 0.003094967920333147\n",
      "Epoch: 3 | Batch ID: 100 | Loss: 0.0031773189548403025\n",
      "Epoch: 3 | Batch ID: 200 | Loss: 0.002016151789575815\n",
      "Epoch: 3 | Batch ID: 300 | Loss: 0.0020693279802799225\n",
      "Epoch: 3 | Batch ID: 400 | Loss: 0.0014311210252344608\n",
      "Epoch: 4 | Batch ID: 0 | Loss: 0.0012449806090444326\n",
      "Epoch: 4 | Batch ID: 100 | Loss: 0.0016285491874441504\n",
      "Epoch: 4 | Batch ID: 200 | Loss: 0.0010121630039066076\n",
      "Epoch: 4 | Batch ID: 300 | Loss: 0.0008406915585510433\n",
      "Epoch: 4 | Batch ID: 400 | Loss: 0.0008481881814077497\n",
      "Epoch: 5 | Batch ID: 0 | Loss: 0.0008747493848204613\n",
      "Epoch: 5 | Batch ID: 100 | Loss: 0.001221228507347405\n",
      "Epoch: 5 | Batch ID: 200 | Loss: 0.0006954218843020499\n",
      "Epoch: 5 | Batch ID: 300 | Loss: 0.0005910635809414089\n",
      "Epoch: 5 | Batch ID: 400 | Loss: 0.0005443217232823372\n",
      "Epoch: 6 | Batch ID: 0 | Loss: 0.0006258236244320869\n",
      "Epoch: 6 | Batch ID: 100 | Loss: 0.0008505706791765988\n",
      "Epoch: 6 | Batch ID: 200 | Loss: 0.0005133025697432458\n",
      "Epoch: 6 | Batch ID: 300 | Loss: 0.00042287580436095595\n",
      "Epoch: 6 | Batch ID: 400 | Loss: 0.00037018765578977764\n",
      "Epoch: 7 | Batch ID: 0 | Loss: 0.00046535974252037704\n",
      "Epoch: 7 | Batch ID: 100 | Loss: 0.0006157928146421909\n",
      "Epoch: 7 | Batch ID: 200 | Loss: 0.0003897859714925289\n",
      "Epoch: 7 | Batch ID: 300 | Loss: 0.0003092589904554188\n",
      "Epoch: 7 | Batch ID: 400 | Loss: 0.0002616272831801325\n",
      "Epoch: 8 | Batch ID: 0 | Loss: 0.00035298074362799525\n",
      "Epoch: 8 | Batch ID: 100 | Loss: 0.00045525655150413513\n",
      "Epoch: 8 | Batch ID: 200 | Loss: 0.00030078590498305857\n",
      "Epoch: 8 | Batch ID: 300 | Loss: 0.00023070462339092046\n",
      "Epoch: 8 | Batch ID: 400 | Loss: 0.0001898852933663875\n",
      "Epoch: 9 | Batch ID: 0 | Loss: 0.00027078762650489807\n",
      "Epoch: 9 | Batch ID: 100 | Loss: 0.0003429531934671104\n",
      "Epoch: 9 | Batch ID: 200 | Loss: 0.00023562040587421507\n",
      "Epoch: 9 | Batch ID: 300 | Loss: 0.000174389046151191\n",
      "Epoch: 9 | Batch ID: 400 | Loss: 0.0001397670857841149\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "my_dataset_loader = torch.utils.data.DataLoader(dataset=my_custom_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(my_model.parameters(), lr=LR)\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    for i, (images, labels) in enumerate(my_dataset_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = my_model(images.float())\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            print(f\"Epoch: {epoch} | Batch ID: {i} | Loss: {loss.data}\")\n",
    "\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "082f4438-9ff4-4a8e-9e95-c0d349b57ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.982010582010582\n",
      "F1 Score: 0.9550892894644688\n"
     ]
    }
   ],
   "source": [
    "valid_dataset = MyCustomDataset(valid_data, transform)\n",
    "\n",
    "valid_dataloader = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "targets = []\n",
    "all_predictions = []\n",
    "\n",
    "for images, labels in valid_dataloader:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        pred = my_model(images.float())\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        \n",
    "        targets.extend(labels.cpu().numpy())\n",
    "        \n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(targets, all_predictions)}\")\n",
    "print(f\"F1 Score: {np.mean(f1_score(targets, all_predictions, average=None))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6eb1e32-f718-4c9d-8afd-17ed569bf549",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTestDataset(Dataset):\n",
    "    def __init__(self, data_info, transform, train=True):\n",
    "        self.data_info = data_info\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.image_path = self.data_info.ImageID.tolist()\n",
    "\n",
    "        self.data_len = len(self.image_path)\n",
    "        \n",
    "        self.train = train\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_thing = Image.open(\"/opt/ml/input/data/eval/images/\" + self.image_path[index])\n",
    "        \n",
    "        if self.transform:\n",
    "            img_thing = self.transform(img_thing)\n",
    "        \n",
    "        return img_thing\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "\n",
    "\n",
    "test_df = pd.read_csv(\"/opt/ml/input/data/eval/info.csv\")\n",
    "    \n",
    "    \n",
    "test_dataset = MyTestDataset(test_df, transform = transform, train=False)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                                batch_size=8,\n",
    "                                                shuffle=False)\n",
    "\n",
    "my_model.eval()\n",
    "\n",
    "all_predictions = []\n",
    "for images in test_dataloader:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = my_model(images.float())\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "\n",
    "\n",
    "test_df['ans'] = all_predictions\n",
    "\n",
    "test_df.to_csv(\"result2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdf3f77-5839-416f-aa28-e80c1111e7a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
