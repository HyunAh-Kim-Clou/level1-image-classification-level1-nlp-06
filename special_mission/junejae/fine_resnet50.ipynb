{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cubic-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchsummary\n",
    "\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from sklearn.metrics import f1_score, fbeta_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0d6f2e8-3dfb-4841-acff-10ff4ea91462",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.0001\n",
    "SEED = 42\n",
    "EPOCH = 10\n",
    "BATCH_SIZE = 70\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "train_dir = '/opt/ml/input/data/train'\n",
    "\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "# torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e22e2508-1af9-4ef4-a8da-bd1a6d9d5b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  4% |  0% |\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  4% |  0% |\n"
     ]
    }
   ],
   "source": [
    "# Flush the GPU's memory\n",
    "import GPUtil\n",
    "GPUtil.showUtilization()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "GPUtil.showUtilization()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0572c10a-acee-4648-9ad8-cf97e07a9992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessedData():\n",
    "    data_info = pd.read_csv(train_dir + '/train.csv', header=0)\n",
    "\n",
    "    prepro_data_info = pd.DataFrame(columns={'id','img_path','race','mask','gender','age','label'})\n",
    "\n",
    "    all_id, all_path, all_race, all_mask, all_age, all_gender, all_label = [],[],[],[],[],[],[]\n",
    "\n",
    "    for absolute_path in glob(train_dir + \"/images/*/*\"):\n",
    "        split_list = absolute_path.split(\"/\")\n",
    "        img_name = split_list[-1]\n",
    "        img_path = split_list[-2]\n",
    "\n",
    "        path_split = img_path.split(\"_\")\n",
    "\n",
    "        img_id = path_split[0]\n",
    "        img_gender = 0 if path_split[1] == \"male\" else 1\n",
    "        img_race = path_split[2]\n",
    "        img_age = min(2, int(path_split[3]) // 30)\n",
    "\n",
    "        img_mask = 0\n",
    "        if 'incorrect' in img_name:\n",
    "            img_mask = 1\n",
    "        elif 'normal' in img_name:\n",
    "            img_mask = 2\n",
    "\n",
    "        all_id.append(img_id)\n",
    "        all_path.append(absolute_path)\n",
    "        all_race.append(img_race)\n",
    "        all_mask.append(img_mask)\n",
    "        all_gender.append(img_gender)\n",
    "        all_age.append(img_age)\n",
    "        all_label.append(img_mask*6 + img_gender*3 + img_age)\n",
    "\n",
    "    prepro_data_info['id'] = all_id\n",
    "    prepro_data_info['img_path'] = all_path\n",
    "    prepro_data_info['race'] = all_race\n",
    "    prepro_data_info['mask'] = all_mask\n",
    "    prepro_data_info['gender'] = all_gender\n",
    "    prepro_data_info['age'] = all_age\n",
    "    prepro_data_info['label'] = all_label\n",
    "    \n",
    "    return prepro_data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85a67b3e-2de1-47b6-85ff-62ec99ba8125",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomDataset(Dataset):\n",
    "    def __init__(self, prepro_data_info, transform, train=True):\n",
    "        self.data_info = prepro_data_info # preprocessFunction()\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.image_path = self.data_info.img_path.tolist()\n",
    "        self.label_arr = self.data_info.label.tolist()\n",
    "\n",
    "        self.data_len = len(self.data_info.img_path)\n",
    "        \n",
    "        self.train = train\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_thing = Image.open(self.image_path[index])\n",
    "        \n",
    "        if self.transform:\n",
    "            img_thing = self.transform(img_thing)\n",
    "        \n",
    "        if self.train:\n",
    "            img_label = self.label_arr[index]\n",
    "            return (img_thing, torch.tensor(img_label))\n",
    "        else:\n",
    "            return img_thing\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c91667f-2592-4eaf-88e0-999716c56857",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MyCustomModel, self).__init__()\n",
    "        \n",
    "        self.resnet50 = models.resnet50(pretrained=True)\n",
    "        \n",
    "        self.resnet50.fc = torch.nn.Linear(in_features=2048, out_features=18, bias=True)\n",
    "        \n",
    "        # initialize\n",
    "        nn.init.xavier_uniform_(self.resnet50.fc.weight)\n",
    "        stdv = 1. / math.sqrt(self.resnet50.fc.weight.size(1))\n",
    "        self.resnet50.fc.bias.data.uniform_(-stdv,stdv)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.resnet50(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3b65151-0797-48f7-b8fa-c43d07fde964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  0% |\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([Resize((512,384),Image.BILINEAR), ToTensor(), Normalize(mean=(0.5,0.5,0.5), std=(0.2,0.2,0.2))])\n",
    "\n",
    "train_data, valid_data = train_test_split(preprocessedData(), test_size=0.2)\n",
    "\n",
    "my_custom_dataset = MyCustomDataset(train_data, transform)\n",
    "\n",
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4913451-d657-4d76-9f47-0b0bb23a793b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCustomModel(\n",
      "  (resnet50): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=2048, out_features=18, bias=True)\n",
      "  )\n",
      ")\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  2% |  4% |\n"
     ]
    }
   ],
   "source": [
    "my_model = MyCustomModel()\n",
    "my_model.to(device)\n",
    "print(my_model)\n",
    "\n",
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5aec7e29-779e-4e24-a544-e02304971dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 192]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 256, 192]             128\n",
      "              ReLU-3         [-1, 64, 256, 192]               0\n",
      "         MaxPool2d-4          [-1, 64, 128, 96]               0\n",
      "            Conv2d-5          [-1, 64, 128, 96]           4,096\n",
      "       BatchNorm2d-6          [-1, 64, 128, 96]             128\n",
      "              ReLU-7          [-1, 64, 128, 96]               0\n",
      "            Conv2d-8          [-1, 64, 128, 96]          36,864\n",
      "       BatchNorm2d-9          [-1, 64, 128, 96]             128\n",
      "             ReLU-10          [-1, 64, 128, 96]               0\n",
      "           Conv2d-11         [-1, 256, 128, 96]          16,384\n",
      "      BatchNorm2d-12         [-1, 256, 128, 96]             512\n",
      "           Conv2d-13         [-1, 256, 128, 96]          16,384\n",
      "      BatchNorm2d-14         [-1, 256, 128, 96]             512\n",
      "             ReLU-15         [-1, 256, 128, 96]               0\n",
      "       Bottleneck-16         [-1, 256, 128, 96]               0\n",
      "           Conv2d-17          [-1, 64, 128, 96]          16,384\n",
      "      BatchNorm2d-18          [-1, 64, 128, 96]             128\n",
      "             ReLU-19          [-1, 64, 128, 96]               0\n",
      "           Conv2d-20          [-1, 64, 128, 96]          36,864\n",
      "      BatchNorm2d-21          [-1, 64, 128, 96]             128\n",
      "             ReLU-22          [-1, 64, 128, 96]               0\n",
      "           Conv2d-23         [-1, 256, 128, 96]          16,384\n",
      "      BatchNorm2d-24         [-1, 256, 128, 96]             512\n",
      "             ReLU-25         [-1, 256, 128, 96]               0\n",
      "       Bottleneck-26         [-1, 256, 128, 96]               0\n",
      "           Conv2d-27          [-1, 64, 128, 96]          16,384\n",
      "      BatchNorm2d-28          [-1, 64, 128, 96]             128\n",
      "             ReLU-29          [-1, 64, 128, 96]               0\n",
      "           Conv2d-30          [-1, 64, 128, 96]          36,864\n",
      "      BatchNorm2d-31          [-1, 64, 128, 96]             128\n",
      "             ReLU-32          [-1, 64, 128, 96]               0\n",
      "           Conv2d-33         [-1, 256, 128, 96]          16,384\n",
      "      BatchNorm2d-34         [-1, 256, 128, 96]             512\n",
      "             ReLU-35         [-1, 256, 128, 96]               0\n",
      "       Bottleneck-36         [-1, 256, 128, 96]               0\n",
      "           Conv2d-37         [-1, 128, 128, 96]          32,768\n",
      "      BatchNorm2d-38         [-1, 128, 128, 96]             256\n",
      "             ReLU-39         [-1, 128, 128, 96]               0\n",
      "           Conv2d-40          [-1, 128, 64, 48]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 64, 48]             256\n",
      "             ReLU-42          [-1, 128, 64, 48]               0\n",
      "           Conv2d-43          [-1, 512, 64, 48]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 64, 48]           1,024\n",
      "           Conv2d-45          [-1, 512, 64, 48]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 64, 48]           1,024\n",
      "             ReLU-47          [-1, 512, 64, 48]               0\n",
      "       Bottleneck-48          [-1, 512, 64, 48]               0\n",
      "           Conv2d-49          [-1, 128, 64, 48]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 64, 48]             256\n",
      "             ReLU-51          [-1, 128, 64, 48]               0\n",
      "           Conv2d-52          [-1, 128, 64, 48]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 64, 48]             256\n",
      "             ReLU-54          [-1, 128, 64, 48]               0\n",
      "           Conv2d-55          [-1, 512, 64, 48]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 64, 48]           1,024\n",
      "             ReLU-57          [-1, 512, 64, 48]               0\n",
      "       Bottleneck-58          [-1, 512, 64, 48]               0\n",
      "           Conv2d-59          [-1, 128, 64, 48]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 64, 48]             256\n",
      "             ReLU-61          [-1, 128, 64, 48]               0\n",
      "           Conv2d-62          [-1, 128, 64, 48]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 64, 48]             256\n",
      "             ReLU-64          [-1, 128, 64, 48]               0\n",
      "           Conv2d-65          [-1, 512, 64, 48]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 64, 48]           1,024\n",
      "             ReLU-67          [-1, 512, 64, 48]               0\n",
      "       Bottleneck-68          [-1, 512, 64, 48]               0\n",
      "           Conv2d-69          [-1, 128, 64, 48]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 64, 48]             256\n",
      "             ReLU-71          [-1, 128, 64, 48]               0\n",
      "           Conv2d-72          [-1, 128, 64, 48]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 64, 48]             256\n",
      "             ReLU-74          [-1, 128, 64, 48]               0\n",
      "           Conv2d-75          [-1, 512, 64, 48]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 64, 48]           1,024\n",
      "             ReLU-77          [-1, 512, 64, 48]               0\n",
      "       Bottleneck-78          [-1, 512, 64, 48]               0\n",
      "           Conv2d-79          [-1, 256, 64, 48]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 64, 48]             512\n",
      "             ReLU-81          [-1, 256, 64, 48]               0\n",
      "           Conv2d-82          [-1, 256, 32, 24]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 32, 24]             512\n",
      "             ReLU-84          [-1, 256, 32, 24]               0\n",
      "           Conv2d-85         [-1, 1024, 32, 24]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 32, 24]           2,048\n",
      "           Conv2d-87         [-1, 1024, 32, 24]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 32, 24]           2,048\n",
      "             ReLU-89         [-1, 1024, 32, 24]               0\n",
      "       Bottleneck-90         [-1, 1024, 32, 24]               0\n",
      "           Conv2d-91          [-1, 256, 32, 24]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 32, 24]             512\n",
      "             ReLU-93          [-1, 256, 32, 24]               0\n",
      "           Conv2d-94          [-1, 256, 32, 24]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 32, 24]             512\n",
      "             ReLU-96          [-1, 256, 32, 24]               0\n",
      "           Conv2d-97         [-1, 1024, 32, 24]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 32, 24]           2,048\n",
      "             ReLU-99         [-1, 1024, 32, 24]               0\n",
      "      Bottleneck-100         [-1, 1024, 32, 24]               0\n",
      "          Conv2d-101          [-1, 256, 32, 24]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 32, 24]             512\n",
      "            ReLU-103          [-1, 256, 32, 24]               0\n",
      "          Conv2d-104          [-1, 256, 32, 24]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 32, 24]             512\n",
      "            ReLU-106          [-1, 256, 32, 24]               0\n",
      "          Conv2d-107         [-1, 1024, 32, 24]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 32, 24]           2,048\n",
      "            ReLU-109         [-1, 1024, 32, 24]               0\n",
      "      Bottleneck-110         [-1, 1024, 32, 24]               0\n",
      "          Conv2d-111          [-1, 256, 32, 24]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 32, 24]             512\n",
      "            ReLU-113          [-1, 256, 32, 24]               0\n",
      "          Conv2d-114          [-1, 256, 32, 24]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 32, 24]             512\n",
      "            ReLU-116          [-1, 256, 32, 24]               0\n",
      "          Conv2d-117         [-1, 1024, 32, 24]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 32, 24]           2,048\n",
      "            ReLU-119         [-1, 1024, 32, 24]               0\n",
      "      Bottleneck-120         [-1, 1024, 32, 24]               0\n",
      "          Conv2d-121          [-1, 256, 32, 24]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 32, 24]             512\n",
      "            ReLU-123          [-1, 256, 32, 24]               0\n",
      "          Conv2d-124          [-1, 256, 32, 24]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 32, 24]             512\n",
      "            ReLU-126          [-1, 256, 32, 24]               0\n",
      "          Conv2d-127         [-1, 1024, 32, 24]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 32, 24]           2,048\n",
      "            ReLU-129         [-1, 1024, 32, 24]               0\n",
      "      Bottleneck-130         [-1, 1024, 32, 24]               0\n",
      "          Conv2d-131          [-1, 256, 32, 24]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 32, 24]             512\n",
      "            ReLU-133          [-1, 256, 32, 24]               0\n",
      "          Conv2d-134          [-1, 256, 32, 24]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 32, 24]             512\n",
      "            ReLU-136          [-1, 256, 32, 24]               0\n",
      "          Conv2d-137         [-1, 1024, 32, 24]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 32, 24]           2,048\n",
      "            ReLU-139         [-1, 1024, 32, 24]               0\n",
      "      Bottleneck-140         [-1, 1024, 32, 24]               0\n",
      "          Conv2d-141          [-1, 512, 32, 24]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 32, 24]           1,024\n",
      "            ReLU-143          [-1, 512, 32, 24]               0\n",
      "          Conv2d-144          [-1, 512, 16, 12]       2,359,296\n",
      "     BatchNorm2d-145          [-1, 512, 16, 12]           1,024\n",
      "            ReLU-146          [-1, 512, 16, 12]               0\n",
      "          Conv2d-147         [-1, 2048, 16, 12]       1,048,576\n",
      "     BatchNorm2d-148         [-1, 2048, 16, 12]           4,096\n",
      "          Conv2d-149         [-1, 2048, 16, 12]       2,097,152\n",
      "     BatchNorm2d-150         [-1, 2048, 16, 12]           4,096\n",
      "            ReLU-151         [-1, 2048, 16, 12]               0\n",
      "      Bottleneck-152         [-1, 2048, 16, 12]               0\n",
      "          Conv2d-153          [-1, 512, 16, 12]       1,048,576\n",
      "     BatchNorm2d-154          [-1, 512, 16, 12]           1,024\n",
      "            ReLU-155          [-1, 512, 16, 12]               0\n",
      "          Conv2d-156          [-1, 512, 16, 12]       2,359,296\n",
      "     BatchNorm2d-157          [-1, 512, 16, 12]           1,024\n",
      "            ReLU-158          [-1, 512, 16, 12]               0\n",
      "          Conv2d-159         [-1, 2048, 16, 12]       1,048,576\n",
      "     BatchNorm2d-160         [-1, 2048, 16, 12]           4,096\n",
      "            ReLU-161         [-1, 2048, 16, 12]               0\n",
      "      Bottleneck-162         [-1, 2048, 16, 12]               0\n",
      "          Conv2d-163          [-1, 512, 16, 12]       1,048,576\n",
      "     BatchNorm2d-164          [-1, 512, 16, 12]           1,024\n",
      "            ReLU-165          [-1, 512, 16, 12]               0\n",
      "          Conv2d-166          [-1, 512, 16, 12]       2,359,296\n",
      "     BatchNorm2d-167          [-1, 512, 16, 12]           1,024\n",
      "            ReLU-168          [-1, 512, 16, 12]               0\n",
      "          Conv2d-169         [-1, 2048, 16, 12]       1,048,576\n",
      "     BatchNorm2d-170         [-1, 2048, 16, 12]           4,096\n",
      "            ReLU-171         [-1, 2048, 16, 12]               0\n",
      "      Bottleneck-172         [-1, 2048, 16, 12]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                   [-1, 18]          36,882\n",
      "          ResNet-175                   [-1, 18]               0\n",
      "================================================================\n",
      "Total params: 23,544,914\n",
      "Trainable params: 23,544,914\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 2.25\n",
      "Forward/backward pass size (MB): 1122.77\n",
      "Params size (MB): 89.82\n",
      "Estimated Total Size (MB): 1214.83\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(my_model, (3, 512, 384), device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f019e5d-f077-42ed-8364-07aa32f7dcb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 10% |  6% |\n",
      "Epoch: 0 | Batch ID: 0 | Loss: 2.937436580657959\n",
      "Epoch: 0 | Batch ID: 10 | Loss: 1.187660574913025\n",
      "Epoch: 0 | Batch ID: 20 | Loss: 0.7394035458564758\n",
      "Epoch: 0 | Batch ID: 30 | Loss: 0.6032805442810059\n",
      "Epoch: 0 | Batch ID: 40 | Loss: 0.6134223341941833\n",
      "Epoch: 0 | Batch ID: 50 | Loss: 0.3912833631038666\n",
      "Epoch: 0 | Batch ID: 60 | Loss: 0.4176862835884094\n",
      "Epoch: 0 | Batch ID: 70 | Loss: 0.278264582157135\n",
      "Epoch: 0 | Batch ID: 80 | Loss: 0.34398314356803894\n",
      "Epoch: 0 | Batch ID: 90 | Loss: 0.35350510478019714\n",
      "Epoch: 0 | Batch ID: 100 | Loss: 0.2944689095020294\n",
      "Epoch: 0 | Batch ID: 110 | Loss: 0.26686549186706543\n",
      "Epoch: 0 | Batch ID: 120 | Loss: 0.22725555300712585\n",
      "Epoch: 0 | Batch ID: 130 | Loss: 0.23949448764324188\n",
      "Epoch: 0 | Batch ID: 140 | Loss: 0.21774521470069885\n",
      "Epoch: 0 | Batch ID: 150 | Loss: 0.23778830468654633\n",
      "Epoch: 0 | Batch ID: 160 | Loss: 0.20537839829921722\n",
      "Epoch: 0 | Batch ID: 170 | Loss: 0.2520565390586853\n",
      "Epoch: 0 | Batch ID: 180 | Loss: 0.2658355236053467\n",
      "Epoch: 0 | Batch ID: 190 | Loss: 0.30499687790870667\n",
      "Epoch: 0 | Batch ID: 200 | Loss: 0.09630165249109268\n",
      "Epoch: 0 | Batch ID: 210 | Loss: 0.21602395176887512\n",
      "Accuracy: 0.9515873015873015\n",
      "F1 Score: 0.8947959639054444\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 86% | 90% |\n",
      "Epoch: 1 | Batch ID: 0 | Loss: 0.14818231761455536\n",
      "Epoch: 1 | Batch ID: 10 | Loss: 0.22189220786094666\n",
      "Epoch: 1 | Batch ID: 20 | Loss: 0.10706990212202072\n",
      "Epoch: 1 | Batch ID: 30 | Loss: 0.16876594722270966\n",
      "Epoch: 1 | Batch ID: 40 | Loss: 0.18713922798633575\n",
      "Epoch: 1 | Batch ID: 50 | Loss: 0.08514557778835297\n",
      "Epoch: 1 | Batch ID: 60 | Loss: 0.04006215184926987\n",
      "Epoch: 1 | Batch ID: 70 | Loss: 0.04638691991567612\n",
      "Epoch: 1 | Batch ID: 80 | Loss: 0.025922898203134537\n",
      "Epoch: 1 | Batch ID: 90 | Loss: 0.038386065512895584\n",
      "Epoch: 1 | Batch ID: 100 | Loss: 0.02812998928129673\n",
      "Epoch: 1 | Batch ID: 110 | Loss: 0.034670427441596985\n",
      "Epoch: 1 | Batch ID: 120 | Loss: 0.03131706640124321\n",
      "Epoch: 1 | Batch ID: 130 | Loss: 0.11970311403274536\n",
      "Epoch: 1 | Batch ID: 140 | Loss: 0.02559899352490902\n",
      "Epoch: 1 | Batch ID: 150 | Loss: 0.040186069905757904\n",
      "Epoch: 1 | Batch ID: 160 | Loss: 0.026322416961193085\n",
      "Epoch: 1 | Batch ID: 170 | Loss: 0.056742019951343536\n",
      "Epoch: 1 | Batch ID: 180 | Loss: 0.029777437448501587\n",
      "Epoch: 1 | Batch ID: 190 | Loss: 0.015537590719759464\n",
      "Epoch: 1 | Batch ID: 200 | Loss: 0.01811559870839119\n",
      "Epoch: 1 | Batch ID: 210 | Loss: 0.059156812727451324\n",
      "Accuracy: 0.9838624338624339\n",
      "F1 Score: 0.9696272884469563\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 90% |\n",
      "Epoch: 2 | Batch ID: 0 | Loss: 0.006212410982698202\n",
      "Epoch: 2 | Batch ID: 10 | Loss: 0.015560810454189777\n",
      "Epoch: 2 | Batch ID: 20 | Loss: 0.026826828718185425\n",
      "Epoch: 2 | Batch ID: 30 | Loss: 0.007542192004621029\n",
      "Epoch: 2 | Batch ID: 40 | Loss: 0.021414345130324364\n",
      "Epoch: 2 | Batch ID: 50 | Loss: 0.013714486733078957\n",
      "Epoch: 2 | Batch ID: 60 | Loss: 0.007218848913908005\n",
      "Epoch: 2 | Batch ID: 70 | Loss: 0.01175023801624775\n",
      "Epoch: 2 | Batch ID: 80 | Loss: 0.004729851149022579\n",
      "Epoch: 2 | Batch ID: 90 | Loss: 0.005297493655234575\n",
      "Epoch: 2 | Batch ID: 100 | Loss: 0.004300396889448166\n",
      "Epoch: 2 | Batch ID: 110 | Loss: 0.005687040276825428\n",
      "Epoch: 2 | Batch ID: 120 | Loss: 0.004247535485774279\n",
      "Epoch: 2 | Batch ID: 130 | Loss: 0.041247569024562836\n",
      "Epoch: 2 | Batch ID: 140 | Loss: 0.02127007581293583\n",
      "Epoch: 2 | Batch ID: 150 | Loss: 0.00481953052803874\n",
      "Epoch: 2 | Batch ID: 160 | Loss: 0.004771646112203598\n",
      "Epoch: 2 | Batch ID: 170 | Loss: 0.006894546560943127\n",
      "Epoch: 2 | Batch ID: 180 | Loss: 0.002663872204720974\n",
      "Epoch: 2 | Batch ID: 190 | Loss: 0.006891746539622545\n",
      "Epoch: 2 | Batch ID: 200 | Loss: 0.004624087829142809\n",
      "Epoch: 2 | Batch ID: 210 | Loss: 0.0018409492913633585\n",
      "Accuracy: 0.9738095238095238\n",
      "F1 Score: 0.9551656427769473\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 90% |\n",
      "Epoch: 3 | Batch ID: 0 | Loss: 0.003665465861558914\n",
      "Epoch: 3 | Batch ID: 10 | Loss: 0.02622883766889572\n",
      "Epoch: 3 | Batch ID: 20 | Loss: 0.007527821231633425\n",
      "Epoch: 3 | Batch ID: 30 | Loss: 0.010792503133416176\n",
      "Epoch: 3 | Batch ID: 40 | Loss: 0.010436823591589928\n",
      "Epoch: 3 | Batch ID: 50 | Loss: 0.060811370611190796\n",
      "Epoch: 3 | Batch ID: 60 | Loss: 0.006106299813836813\n",
      "Epoch: 3 | Batch ID: 70 | Loss: 0.007222023326903582\n",
      "Epoch: 3 | Batch ID: 80 | Loss: 0.006941981613636017\n",
      "Epoch: 3 | Batch ID: 90 | Loss: 0.0051549202762544155\n",
      "Epoch: 3 | Batch ID: 100 | Loss: 0.00560808926820755\n",
      "Epoch: 3 | Batch ID: 110 | Loss: 0.04429594427347183\n",
      "Epoch: 3 | Batch ID: 120 | Loss: 0.007909041829407215\n",
      "Epoch: 3 | Batch ID: 130 | Loss: 0.009934862144291401\n",
      "Epoch: 3 | Batch ID: 140 | Loss: 0.014478741213679314\n",
      "Epoch: 3 | Batch ID: 150 | Loss: 0.008689478039741516\n",
      "Epoch: 3 | Batch ID: 160 | Loss: 0.0045153433457016945\n",
      "Epoch: 3 | Batch ID: 170 | Loss: 0.009787723422050476\n",
      "Epoch: 3 | Batch ID: 180 | Loss: 0.012750481255352497\n",
      "Epoch: 3 | Batch ID: 190 | Loss: 0.01159963570535183\n",
      "Epoch: 3 | Batch ID: 200 | Loss: 0.0034458129666745663\n",
      "Epoch: 3 | Batch ID: 210 | Loss: 0.004368350375443697\n",
      "Accuracy: 0.9835978835978836\n",
      "F1 Score: 0.9644235163507032\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 90% |\n",
      "Epoch: 4 | Batch ID: 0 | Loss: 0.0033965532202273607\n",
      "Epoch: 4 | Batch ID: 10 | Loss: 0.032764535397291183\n",
      "Epoch: 4 | Batch ID: 20 | Loss: 0.011127270758152008\n",
      "Epoch: 4 | Batch ID: 30 | Loss: 0.008769441395998001\n",
      "Epoch: 4 | Batch ID: 40 | Loss: 0.008661383762955666\n",
      "Epoch: 4 | Batch ID: 50 | Loss: 0.018463557586073875\n",
      "Epoch: 4 | Batch ID: 60 | Loss: 0.013860776089131832\n",
      "Epoch: 4 | Batch ID: 70 | Loss: 0.006631284020841122\n",
      "Epoch: 4 | Batch ID: 80 | Loss: 0.006454584654420614\n",
      "Epoch: 4 | Batch ID: 90 | Loss: 0.014210040681064129\n",
      "Epoch: 4 | Batch ID: 100 | Loss: 0.011448835022747517\n",
      "Epoch: 4 | Batch ID: 110 | Loss: 0.001867892686277628\n",
      "Epoch: 4 | Batch ID: 120 | Loss: 0.005433555692434311\n",
      "Epoch: 4 | Batch ID: 130 | Loss: 0.015571440570056438\n",
      "Epoch: 4 | Batch ID: 140 | Loss: 0.0024836284574121237\n",
      "Epoch: 4 | Batch ID: 150 | Loss: 0.005732966586947441\n",
      "Epoch: 4 | Batch ID: 160 | Loss: 0.0033359485678374767\n",
      "Epoch: 4 | Batch ID: 170 | Loss: 0.014666331000626087\n",
      "Epoch: 4 | Batch ID: 180 | Loss: 0.028995350003242493\n",
      "Epoch: 4 | Batch ID: 190 | Loss: 0.018172314390540123\n",
      "Epoch: 4 | Batch ID: 200 | Loss: 0.04223271459341049\n",
      "Epoch: 4 | Batch ID: 210 | Loss: 0.0998561754822731\n",
      "Accuracy: 0.9576719576719577\n",
      "F1 Score: 0.9295745421379434\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 88% | 90% |\n",
      "Epoch: 5 | Batch ID: 0 | Loss: 0.021059947088360786\n",
      "Epoch: 5 | Batch ID: 10 | Loss: 0.2099759876728058\n",
      "Epoch: 5 | Batch ID: 20 | Loss: 0.012434895150363445\n",
      "Epoch: 5 | Batch ID: 30 | Loss: 0.017734959721565247\n",
      "Epoch: 5 | Batch ID: 40 | Loss: 0.08810833841562271\n",
      "Epoch: 5 | Batch ID: 50 | Loss: 0.06513785570859909\n",
      "Epoch: 5 | Batch ID: 60 | Loss: 0.02568485215306282\n",
      "Epoch: 5 | Batch ID: 70 | Loss: 0.043436724692583084\n",
      "Epoch: 5 | Batch ID: 80 | Loss: 0.05728476494550705\n",
      "Epoch: 5 | Batch ID: 90 | Loss: 0.027055839076638222\n",
      "Epoch: 5 | Batch ID: 100 | Loss: 0.027930404990911484\n",
      "Epoch: 5 | Batch ID: 110 | Loss: 0.02415318973362446\n",
      "Epoch: 5 | Batch ID: 120 | Loss: 0.08263830095529556\n",
      "Epoch: 5 | Batch ID: 130 | Loss: 0.1260630190372467\n",
      "Epoch: 5 | Batch ID: 140 | Loss: 0.08328846842050552\n",
      "Epoch: 5 | Batch ID: 150 | Loss: 0.07443945109844208\n",
      "Epoch: 5 | Batch ID: 160 | Loss: 0.011704518459737301\n",
      "Epoch: 5 | Batch ID: 170 | Loss: 0.024305669590830803\n",
      "Epoch: 5 | Batch ID: 180 | Loss: 0.09739454090595245\n",
      "Epoch: 5 | Batch ID: 190 | Loss: 0.051047153770923615\n",
      "Epoch: 5 | Batch ID: 200 | Loss: 0.005272642243653536\n",
      "Epoch: 5 | Batch ID: 210 | Loss: 0.005149463657289743\n",
      "Accuracy: 0.9793650793650793\n",
      "F1 Score: 0.9675024747817252\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 90% |\n",
      "Epoch: 6 | Batch ID: 0 | Loss: 0.012417218647897243\n",
      "Epoch: 6 | Batch ID: 10 | Loss: 0.03369579836726189\n",
      "Epoch: 6 | Batch ID: 20 | Loss: 0.06884236633777618\n",
      "Epoch: 6 | Batch ID: 30 | Loss: 0.014304148964583874\n",
      "Epoch: 6 | Batch ID: 40 | Loss: 0.007894810289144516\n",
      "Epoch: 6 | Batch ID: 50 | Loss: 0.020515790209174156\n",
      "Epoch: 6 | Batch ID: 60 | Loss: 0.020404310896992683\n",
      "Epoch: 6 | Batch ID: 70 | Loss: 0.014567405916750431\n",
      "Epoch: 6 | Batch ID: 80 | Loss: 0.005071611143648624\n",
      "Epoch: 6 | Batch ID: 90 | Loss: 0.0035012708976864815\n",
      "Epoch: 6 | Batch ID: 100 | Loss: 0.07108397036790848\n",
      "Epoch: 6 | Batch ID: 110 | Loss: 0.022040851414203644\n",
      "Epoch: 6 | Batch ID: 120 | Loss: 0.04670748487114906\n",
      "Epoch: 6 | Batch ID: 130 | Loss: 0.008507386781275272\n",
      "Epoch: 6 | Batch ID: 140 | Loss: 0.028392180800437927\n",
      "Epoch: 6 | Batch ID: 150 | Loss: 0.01476731151342392\n",
      "Epoch: 6 | Batch ID: 160 | Loss: 0.0070904092863202095\n",
      "Epoch: 6 | Batch ID: 170 | Loss: 0.00303854513913393\n",
      "Epoch: 6 | Batch ID: 180 | Loss: 0.003169164527207613\n",
      "Epoch: 6 | Batch ID: 190 | Loss: 0.00500515615567565\n",
      "Epoch: 6 | Batch ID: 200 | Loss: 0.0016549235442653298\n",
      "Epoch: 6 | Batch ID: 210 | Loss: 0.002175653353333473\n",
      "Accuracy: 0.9888888888888889\n",
      "F1 Score: 0.9707815901716282\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 90% |\n",
      "Epoch: 7 | Batch ID: 0 | Loss: 0.0011144737945869565\n",
      "Epoch: 7 | Batch ID: 10 | Loss: 0.0040710000321269035\n",
      "Epoch: 7 | Batch ID: 20 | Loss: 0.00170082226395607\n",
      "Epoch: 7 | Batch ID: 30 | Loss: 0.0010987475980073214\n",
      "Epoch: 7 | Batch ID: 40 | Loss: 0.007191395852714777\n",
      "Epoch: 7 | Batch ID: 50 | Loss: 0.003107108874246478\n",
      "Epoch: 7 | Batch ID: 60 | Loss: 0.004538213834166527\n",
      "Epoch: 7 | Batch ID: 70 | Loss: 0.0005832634633406997\n",
      "Epoch: 7 | Batch ID: 80 | Loss: 0.0006837412365712225\n",
      "Epoch: 7 | Batch ID: 90 | Loss: 0.0007220855914056301\n",
      "Epoch: 7 | Batch ID: 100 | Loss: 0.0046162232756614685\n",
      "Epoch: 7 | Batch ID: 110 | Loss: 0.0006099219899624586\n",
      "Epoch: 7 | Batch ID: 120 | Loss: 0.0004917318001389503\n",
      "Epoch: 7 | Batch ID: 130 | Loss: 0.0023137368261814117\n",
      "Epoch: 7 | Batch ID: 140 | Loss: 0.0009266184060834348\n",
      "Epoch: 7 | Batch ID: 150 | Loss: 0.0019346941262483597\n",
      "Epoch: 7 | Batch ID: 160 | Loss: 0.00043774163350462914\n",
      "Epoch: 7 | Batch ID: 170 | Loss: 0.0014138008700683713\n",
      "Epoch: 7 | Batch ID: 180 | Loss: 0.00033847635495476425\n",
      "Epoch: 7 | Batch ID: 190 | Loss: 0.0007508939597755671\n",
      "Epoch: 7 | Batch ID: 200 | Loss: 0.00045579858124256134\n",
      "Epoch: 7 | Batch ID: 210 | Loss: 0.0006234977627173066\n",
      "Accuracy: 0.9925925925925926\n",
      "F1 Score: 0.9818994167897134\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 90% |\n",
      "Epoch: 8 | Batch ID: 0 | Loss: 0.0002461769909132272\n",
      "Epoch: 8 | Batch ID: 10 | Loss: 0.00027638746541924775\n",
      "Epoch: 8 | Batch ID: 20 | Loss: 0.0003827656910289079\n",
      "Epoch: 8 | Batch ID: 30 | Loss: 0.0003221913648303598\n",
      "Epoch: 8 | Batch ID: 40 | Loss: 0.0004669217742048204\n",
      "Epoch: 8 | Batch ID: 50 | Loss: 0.0007530202274210751\n",
      "Epoch: 8 | Batch ID: 60 | Loss: 0.00047152399201877415\n",
      "Epoch: 8 | Batch ID: 70 | Loss: 0.00021440615819301456\n",
      "Epoch: 8 | Batch ID: 80 | Loss: 0.0003358231915626675\n",
      "Epoch: 8 | Batch ID: 90 | Loss: 0.00033985593472607434\n",
      "Epoch: 8 | Batch ID: 100 | Loss: 0.0003811432980000973\n",
      "Epoch: 8 | Batch ID: 110 | Loss: 0.00029473501490429044\n",
      "Epoch: 8 | Batch ID: 120 | Loss: 0.0002708433894440532\n",
      "Epoch: 8 | Batch ID: 130 | Loss: 0.0006673653260804713\n",
      "Epoch: 8 | Batch ID: 140 | Loss: 0.0005702624912373722\n",
      "Epoch: 8 | Batch ID: 150 | Loss: 0.0004816048895008862\n",
      "Epoch: 8 | Batch ID: 160 | Loss: 0.0002505806914996356\n",
      "Epoch: 8 | Batch ID: 170 | Loss: 0.0006978470482863486\n",
      "Epoch: 8 | Batch ID: 180 | Loss: 0.00024927061167545617\n",
      "Epoch: 8 | Batch ID: 190 | Loss: 0.0005401083617471159\n",
      "Epoch: 8 | Batch ID: 200 | Loss: 0.0002844310365617275\n",
      "Epoch: 8 | Batch ID: 210 | Loss: 0.0002693374699447304\n",
      "Accuracy: 0.9933862433862434\n",
      "F1 Score: 0.9851852752683049\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 | 100% | 90% |\n",
      "Epoch: 9 | Batch ID: 0 | Loss: 0.00017495162319391966\n",
      "Epoch: 9 | Batch ID: 10 | Loss: 0.00017039748490788043\n",
      "Epoch: 9 | Batch ID: 20 | Loss: 0.00026344266370870173\n",
      "Epoch: 9 | Batch ID: 30 | Loss: 0.0002052978816209361\n",
      "Epoch: 9 | Batch ID: 40 | Loss: 0.00031441968167200685\n",
      "Epoch: 9 | Batch ID: 50 | Loss: 0.0005064025754109025\n",
      "Epoch: 9 | Batch ID: 60 | Loss: 0.0003100492467638105\n",
      "Epoch: 9 | Batch ID: 70 | Loss: 0.00013304683670867234\n",
      "Epoch: 9 | Batch ID: 80 | Loss: 0.00023862789385020733\n",
      "Epoch: 9 | Batch ID: 90 | Loss: 0.00023453810717910528\n",
      "Epoch: 9 | Batch ID: 100 | Loss: 0.0002651434624567628\n",
      "Epoch: 9 | Batch ID: 110 | Loss: 0.00022087972320150584\n",
      "Epoch: 9 | Batch ID: 120 | Loss: 0.00019952304137405008\n",
      "Epoch: 9 | Batch ID: 130 | Loss: 0.000489397207275033\n",
      "Epoch: 9 | Batch ID: 140 | Loss: 0.0004483296943362802\n",
      "Epoch: 9 | Batch ID: 150 | Loss: 0.0003629550919868052\n",
      "Epoch: 9 | Batch ID: 160 | Loss: 0.00018312466272618622\n",
      "Epoch: 9 | Batch ID: 170 | Loss: 0.0005083278520032763\n",
      "Epoch: 9 | Batch ID: 180 | Loss: 0.00020002084784209728\n",
      "Epoch: 9 | Batch ID: 190 | Loss: 0.00042716521420516074\n",
      "Epoch: 9 | Batch ID: 200 | Loss: 0.0002171281521441415\n",
      "Epoch: 9 | Batch ID: 210 | Loss: 0.00020096410298720002\n",
      "Accuracy: 0.9933862433862434\n",
      "F1 Score: 0.9836448687849568\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 87% | 90% |\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "my_dataset_loader = torch.utils.data.DataLoader(dataset=my_custom_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "valid_dataset = MyCustomDataset(valid_data, transform)\n",
    "\n",
    "valid_dataloader = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(my_model.parameters(), lr=LR)\n",
    "\n",
    "GPUtil.showUtilization()\n",
    "\n",
    "# Start Training\n",
    "for epoch in range(EPOCH):\n",
    "    for i, (images, labels) in enumerate(my_dataset_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = my_model(images.float())\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%10 == 0:\n",
    "            print(f\"Epoch: {epoch} | Batch ID: {i} | Loss: {loss.data}\")\n",
    "            \n",
    "    # Validation Test\n",
    "    targets = []\n",
    "    all_predictions = []\n",
    "\n",
    "    for images, labels in valid_dataloader:\n",
    "        with torch.no_grad():\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            pred = my_model(images.float())\n",
    "            pred = pred.argmax(dim=-1)\n",
    "\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "\n",
    "            all_predictions.extend(pred.cpu().numpy())\n",
    "\n",
    "    print(f\"Accuracy: {accuracy_score(targets, all_predictions)}\")\n",
    "    print(f\"F1 Score: {np.mean(f1_score(targets, all_predictions, average=None))}\")\n",
    "    GPUtil.showUtilization()\n",
    "            \n",
    "\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6eb1e32-f718-4c9d-8afd-17ed569bf549",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "class MyTestDataset(Dataset):\n",
    "    def __init__(self, data_info, transform, train=True):\n",
    "        self.data_info = data_info\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.image_path = self.data_info.ImageID.tolist()\n",
    "\n",
    "        self.data_len = len(self.image_path)\n",
    "        \n",
    "        self.train = train\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_thing = Image.open(\"/opt/ml/input/data/eval/images/\" + self.image_path[index])\n",
    "        \n",
    "        if self.transform:\n",
    "            img_thing = self.transform(img_thing)\n",
    "        \n",
    "        return img_thing\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "\n",
    "\n",
    "test_df = pd.read_csv(\"/opt/ml/input/data/eval/info.csv\")\n",
    "    \n",
    "    \n",
    "test_dataset = MyTestDataset(test_df, transform = transform, train=False)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                                batch_size=8,\n",
    "                                                shuffle=False)\n",
    "\n",
    "my_model.eval()\n",
    "\n",
    "all_predictions = []\n",
    "for images in test_dataloader:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = my_model(images.float())\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "\n",
    "\n",
    "test_df['ans'] = all_predictions\n",
    "\n",
    "test_df.to_csv(\"result5.csv\", index=False)\n",
    "\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdf3f77-5839-416f-aa28-e80c1111e7a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
