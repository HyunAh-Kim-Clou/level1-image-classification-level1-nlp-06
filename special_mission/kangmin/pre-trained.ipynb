{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d43e8821-38c8-40c2-aaae-45cd61966ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "import math\n",
    "import wandb\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from sklearn.metrics import f1_score, fbeta_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7daceea-b7c9-4ac2-8b57-fcc38358d8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1c65yxlu) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3421... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>f1_score</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.46772</td></tr><tr><td>f1_score</td><td>0.22928</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">azure-oath-2</strong>: <a href=\"https://wandb.ai/lkm/uncategorized/runs/1c65yxlu\" target=\"_blank\">https://wandb.ai/lkm/uncategorized/runs/1c65yxlu</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220224_021308-1c65yxlu/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1c65yxlu). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/lkm/uncategorized/runs/1lcpn4z3\" target=\"_blank\">blooming-pond-3</a></strong> to <a href=\"https://wandb.ai/lkm/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/lkm/uncategorized/runs/1lcpn4z3?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fc98fd5db20>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47035a4b-fdeb-4416-96c9-294dd91c665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.run.name = 'resnet-run-test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e5e29ad-4498-4456-8436-25e700f9b936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>img_path</th>\n",
       "      <th>age</th>\n",
       "      <th>age_group</th>\n",
       "      <th>mask</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>000001</td>\n",
       "      <td>female</td>\n",
       "      <td>/opt/ml/input/data/train/images/000001_female_...</td>\n",
       "      <td>45</td>\n",
       "      <td>&gt;= 30 and &lt; 60</td>\n",
       "      <td>mask</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>000001</td>\n",
       "      <td>female</td>\n",
       "      <td>/opt/ml/input/data/train/images/000001_female_...</td>\n",
       "      <td>45</td>\n",
       "      <td>&gt;= 30 and &lt; 60</td>\n",
       "      <td>mask</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>000001</td>\n",
       "      <td>female</td>\n",
       "      <td>/opt/ml/input/data/train/images/000001_female_...</td>\n",
       "      <td>45</td>\n",
       "      <td>&gt;= 30 and &lt; 60</td>\n",
       "      <td>normal</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>000001</td>\n",
       "      <td>female</td>\n",
       "      <td>/opt/ml/input/data/train/images/000001_female_...</td>\n",
       "      <td>45</td>\n",
       "      <td>&gt;= 30 and &lt; 60</td>\n",
       "      <td>incorrect_mask</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>000001</td>\n",
       "      <td>female</td>\n",
       "      <td>/opt/ml/input/data/train/images/000001_female_...</td>\n",
       "      <td>45</td>\n",
       "      <td>&gt;= 30 and &lt; 60</td>\n",
       "      <td>mask</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18895</th>\n",
       "      <td>18895</td>\n",
       "      <td>006959</td>\n",
       "      <td>male</td>\n",
       "      <td>/opt/ml/input/data/train/images/006959_male_As...</td>\n",
       "      <td>19</td>\n",
       "      <td>&lt; 30</td>\n",
       "      <td>normal</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18896</th>\n",
       "      <td>18896</td>\n",
       "      <td>006959</td>\n",
       "      <td>male</td>\n",
       "      <td>/opt/ml/input/data/train/images/006959_male_As...</td>\n",
       "      <td>19</td>\n",
       "      <td>&lt; 30</td>\n",
       "      <td>incorrect_mask</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18897</th>\n",
       "      <td>18897</td>\n",
       "      <td>006959</td>\n",
       "      <td>male</td>\n",
       "      <td>/opt/ml/input/data/train/images/006959_male_As...</td>\n",
       "      <td>19</td>\n",
       "      <td>&lt; 30</td>\n",
       "      <td>mask</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18898</th>\n",
       "      <td>18898</td>\n",
       "      <td>006959</td>\n",
       "      <td>male</td>\n",
       "      <td>/opt/ml/input/data/train/images/006959_male_As...</td>\n",
       "      <td>19</td>\n",
       "      <td>&lt; 30</td>\n",
       "      <td>mask</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18899</th>\n",
       "      <td>18899</td>\n",
       "      <td>006959</td>\n",
       "      <td>male</td>\n",
       "      <td>/opt/ml/input/data/train/images/006959_male_As...</td>\n",
       "      <td>19</td>\n",
       "      <td>&lt; 30</td>\n",
       "      <td>mask</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18900 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0      id  gender  \\\n",
       "0               0  000001  female   \n",
       "1               1  000001  female   \n",
       "2               2  000001  female   \n",
       "3               3  000001  female   \n",
       "4               4  000001  female   \n",
       "...           ...     ...     ...   \n",
       "18895       18895  006959    male   \n",
       "18896       18896  006959    male   \n",
       "18897       18897  006959    male   \n",
       "18898       18898  006959    male   \n",
       "18899       18899  006959    male   \n",
       "\n",
       "                                                img_path  age       age_group  \\\n",
       "0      /opt/ml/input/data/train/images/000001_female_...   45  >= 30 and < 60   \n",
       "1      /opt/ml/input/data/train/images/000001_female_...   45  >= 30 and < 60   \n",
       "2      /opt/ml/input/data/train/images/000001_female_...   45  >= 30 and < 60   \n",
       "3      /opt/ml/input/data/train/images/000001_female_...   45  >= 30 and < 60   \n",
       "4      /opt/ml/input/data/train/images/000001_female_...   45  >= 30 and < 60   \n",
       "...                                                  ...  ...             ...   \n",
       "18895  /opt/ml/input/data/train/images/006959_male_As...   19            < 30   \n",
       "18896  /opt/ml/input/data/train/images/006959_male_As...   19            < 30   \n",
       "18897  /opt/ml/input/data/train/images/006959_male_As...   19            < 30   \n",
       "18898  /opt/ml/input/data/train/images/006959_male_As...   19            < 30   \n",
       "18899  /opt/ml/input/data/train/images/006959_male_As...   19            < 30   \n",
       "\n",
       "                 mask  class  \n",
       "0                mask      4  \n",
       "1                mask      4  \n",
       "2              normal     16  \n",
       "3      incorrect_mask     10  \n",
       "4                mask      4  \n",
       "...               ...    ...  \n",
       "18895          normal     12  \n",
       "18896  incorrect_mask      6  \n",
       "18897            mask      0  \n",
       "18898            mask      0  \n",
       "18899            mask      0  \n",
       "\n",
       "[18900 rows x 8 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = '/opt/ml/input/data/train'\n",
    "train_df = pd.read_csv('/opt/ml/input/data/train/train_data_total.csv')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "03607d4a-f024-429e-8a69-d73ee6b25b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df_data, train=True):\n",
    "        self.data = df_data\n",
    "        self.label = self.data['class'].tolist()\n",
    "        self.img_path = self.data['img_path'].tolist()\n",
    "        \n",
    "        self.transform = transforms.ToTensor()\n",
    "\n",
    "        self.train = train\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_path[index])\n",
    "        img = img.resize((32, 32))\n",
    "        img = np.asarray(img)/255\n",
    "        \n",
    "        img_tensor = self.transform(img)\n",
    "        \n",
    "        if self.train:\n",
    "            return (self.label[index], img_tensor)\n",
    "        else:\n",
    "            return img_tnesor\n",
    "        \n",
    "        \n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "766858f8-ba45-48ce-a69e-36270f3f3ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "TEST_SIZE =0.15\n",
    "train_set, valid_set = train_test_split(train_df, test_size=TEST_SIZE, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e85c3d47-9dae-4d74-918a-b300ff4bb07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16065, 8) (2835, 8)\n"
     ]
    }
   ],
   "source": [
    "print(train_set.shape, valid_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8bcda831-9fa3-436a-bdaf-46f4c39ef708",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_set)\n",
    "valid_dataset = CustomDataset(valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "40fbf43f-982a-4e41-a1f3-c429fca6ef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_model = torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "46ef2fc0-fa1c-4c02-a37b-53e128a74d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 7\n",
    "train_dataset_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "valid_dataset_loader = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "dataloaders = {\n",
    "    \"train\" : train_dataset_loader,\n",
    "    \"test\" : valid_dataset_loader\n",
    "}\n",
    "\n",
    "class_num = 18\n",
    "pre_model.fc = torch.nn.Linear(in_features=512, out_features=class_num, bias=True)\n",
    "torch.nn.init.xavier_uniform_(pre_model.fc.weight)\n",
    "\n",
    "stdv = 1. / math.sqrt(pre_model.fc.weight.size(1))\n",
    "pre_model.fc.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "pre_model.to(device)\n",
    "\n",
    "LEARNING_RATE = 0.0001\n",
    "NUM_EPOCH = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4cd863-2169-462b-a251-f830750368cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eopch: 0 | Batch ID: 0 | Loss: 4.062315464019775\n",
      "Eopch: 0 | Batch ID: 200 | Loss: 3.099478244781494\n",
      "Eopch: 0 | Batch ID: 400 | Loss: 2.831279754638672\n",
      "Eopch: 0 | Batch ID: 600 | Loss: 1.8681915998458862\n",
      "Eopch: 0 | Batch ID: 800 | Loss: 1.9934724569320679\n",
      "Eopch: 0 | Batch ID: 1000 | Loss: 2.6563308238983154\n",
      "Eopch: 0 | Batch ID: 1200 | Loss: 1.5240802764892578\n",
      "Eopch: 0 | Batch ID: 1400 | Loss: 1.2494004964828491\n",
      "Eopch: 0 | Batch ID: 1600 | Loss: 3.1018223762512207\n",
      "Eopch: 0 | Batch ID: 1800 | Loss: 1.2552002668380737\n",
      "Eopch: 0 | Batch ID: 2000 | Loss: 2.4217803478240967\n",
      "Eopch: 0 | Batch ID: 2200 | Loss: 2.338005304336548\n",
      "\n",
      "Eopch: 1 | Batch ID: 0 | Loss: 2.3525519371032715\n",
      "Eopch: 1 | Batch ID: 200 | Loss: 1.0701574087142944\n",
      "Eopch: 1 | Batch ID: 400 | Loss: 1.31036376953125\n",
      "Eopch: 1 | Batch ID: 600 | Loss: 0.9753339886665344\n",
      "Eopch: 1 | Batch ID: 800 | Loss: 1.192132830619812\n",
      "Eopch: 1 | Batch ID: 1000 | Loss: 2.2136075496673584\n",
      "Eopch: 1 | Batch ID: 1200 | Loss: 1.4142581224441528\n",
      "Eopch: 1 | Batch ID: 1400 | Loss: 0.8765334486961365\n",
      "Eopch: 1 | Batch ID: 1600 | Loss: 2.7023518085479736\n",
      "Eopch: 1 | Batch ID: 1800 | Loss: 0.7925559282302856\n",
      "Eopch: 1 | Batch ID: 2000 | Loss: 1.9114998579025269\n",
      "Eopch: 1 | Batch ID: 2200 | Loss: 1.8019053936004639\n",
      "\n",
      "Eopch: 2 | Batch ID: 0 | Loss: 2.0198135375976562\n",
      "Eopch: 2 | Batch ID: 200 | Loss: 1.069098711013794\n",
      "Eopch: 2 | Batch ID: 400 | Loss: 0.7435302138328552\n",
      "Eopch: 2 | Batch ID: 600 | Loss: 0.7658798098564148\n",
      "Eopch: 2 | Batch ID: 800 | Loss: 0.7388754487037659\n",
      "Eopch: 2 | Batch ID: 1000 | Loss: 0.6007652282714844\n",
      "Eopch: 2 | Batch ID: 1200 | Loss: 0.562837541103363\n",
      "Eopch: 2 | Batch ID: 1400 | Loss: 0.8384724855422974\n",
      "Eopch: 2 | Batch ID: 1600 | Loss: 1.7900077104568481\n",
      "Eopch: 2 | Batch ID: 1800 | Loss: 0.31695982813835144\n",
      "Eopch: 2 | Batch ID: 2000 | Loss: 1.1448856592178345\n",
      "Eopch: 2 | Batch ID: 2200 | Loss: 1.3990147113800049\n",
      "\n",
      "Eopch: 3 | Batch ID: 0 | Loss: 1.7878389358520508\n",
      "Eopch: 3 | Batch ID: 200 | Loss: 0.7600588798522949\n",
      "Eopch: 3 | Batch ID: 400 | Loss: 0.8339166641235352\n",
      "Eopch: 3 | Batch ID: 600 | Loss: 0.2336738556623459\n",
      "Eopch: 3 | Batch ID: 800 | Loss: 0.2281693071126938\n",
      "Eopch: 3 | Batch ID: 1000 | Loss: 0.6432219743728638\n",
      "Eopch: 3 | Batch ID: 1200 | Loss: 0.30881908535957336\n",
      "Eopch: 3 | Batch ID: 1400 | Loss: 0.2967367172241211\n",
      "Eopch: 3 | Batch ID: 1600 | Loss: 1.1697790622711182\n",
      "Eopch: 3 | Batch ID: 1800 | Loss: 0.28009316325187683\n",
      "Eopch: 3 | Batch ID: 2000 | Loss: 0.7227901220321655\n",
      "Eopch: 3 | Batch ID: 2200 | Loss: 1.4579746723175049\n",
      "\n",
      "Eopch: 4 | Batch ID: 0 | Loss: 1.1090489625930786\n",
      "Eopch: 4 | Batch ID: 200 | Loss: 0.8695451617240906\n",
      "Eopch: 4 | Batch ID: 400 | Loss: 0.8345885276794434\n",
      "Eopch: 4 | Batch ID: 600 | Loss: 0.25191497802734375\n",
      "Eopch: 4 | Batch ID: 800 | Loss: 0.43638113141059875\n",
      "Eopch: 4 | Batch ID: 1000 | Loss: 0.21447202563285828\n",
      "Eopch: 4 | Batch ID: 1200 | Loss: 0.0752197876572609\n",
      "Eopch: 4 | Batch ID: 1400 | Loss: 0.31032729148864746\n",
      "Eopch: 4 | Batch ID: 1600 | Loss: 0.7832067608833313\n",
      "Eopch: 4 | Batch ID: 1800 | Loss: 0.3648219108581543\n",
      "Eopch: 4 | Batch ID: 2000 | Loss: 0.19988298416137695\n",
      "Eopch: 4 | Batch ID: 2200 | Loss: 1.0259531736373901\n",
      "\n",
      "Eopch: 5 | Batch ID: 0 | Loss: 0.7479629516601562\n",
      "Eopch: 5 | Batch ID: 200 | Loss: 0.9380106329917908\n",
      "Eopch: 5 | Batch ID: 400 | Loss: 0.247426837682724\n",
      "Eopch: 5 | Batch ID: 600 | Loss: 0.15027952194213867\n",
      "Eopch: 5 | Batch ID: 800 | Loss: 0.06757771968841553\n",
      "Eopch: 5 | Batch ID: 1000 | Loss: 0.3392200469970703\n",
      "Eopch: 5 | Batch ID: 1200 | Loss: 0.07103171199560165\n",
      "Eopch: 5 | Batch ID: 1400 | Loss: 0.1448884904384613\n",
      "Eopch: 5 | Batch ID: 1600 | Loss: 0.4535386860370636\n",
      "Eopch: 5 | Batch ID: 1800 | Loss: 0.04995104297995567\n",
      "Eopch: 5 | Batch ID: 2000 | Loss: 0.06412147730588913\n",
      "Eopch: 5 | Batch ID: 2200 | Loss: 0.46064630150794983\n",
      "\n",
      "Eopch: 6 | Batch ID: 0 | Loss: 0.5136638283729553\n",
      "Eopch: 6 | Batch ID: 200 | Loss: 0.13344334065914154\n",
      "Eopch: 6 | Batch ID: 400 | Loss: 0.503929078578949\n",
      "Eopch: 6 | Batch ID: 600 | Loss: 0.05119340866804123\n",
      "Eopch: 6 | Batch ID: 800 | Loss: 0.3447062075138092\n",
      "Eopch: 6 | Batch ID: 1000 | Loss: 0.07658017426729202\n",
      "Eopch: 6 | Batch ID: 1200 | Loss: 0.2665388286113739\n",
      "Eopch: 6 | Batch ID: 1400 | Loss: 0.3595297634601593\n",
      "Eopch: 6 | Batch ID: 1600 | Loss: 0.42896851897239685\n",
      "Eopch: 6 | Batch ID: 1800 | Loss: 0.04077345132827759\n",
      "Eopch: 6 | Batch ID: 2000 | Loss: 0.2042762041091919\n",
      "Eopch: 6 | Batch ID: 2200 | Loss: 0.3010188639163971\n",
      "\n",
      "Eopch: 7 | Batch ID: 0 | Loss: 0.17513272166252136\n",
      "Eopch: 7 | Batch ID: 200 | Loss: 0.08943440765142441\n",
      "Eopch: 7 | Batch ID: 400 | Loss: 0.33637720346450806\n",
      "Eopch: 7 | Batch ID: 600 | Loss: 0.035870254039764404\n",
      "Eopch: 7 | Batch ID: 800 | Loss: 0.19349853694438934\n",
      "Eopch: 7 | Batch ID: 1000 | Loss: 0.46501949429512024\n",
      "Eopch: 7 | Batch ID: 1200 | Loss: 0.00821338128298521\n",
      "Eopch: 7 | Batch ID: 1400 | Loss: 0.29386359453201294\n",
      "Eopch: 7 | Batch ID: 1600 | Loss: 0.1627727448940277\n",
      "Eopch: 7 | Batch ID: 1800 | Loss: 0.3123086988925934\n",
      "Eopch: 7 | Batch ID: 2000 | Loss: 0.05042170733213425\n",
      "Eopch: 7 | Batch ID: 2200 | Loss: 0.6020596623420715\n",
      "\n",
      "Eopch: 8 | Batch ID: 0 | Loss: 0.9211414456367493\n",
      "Eopch: 8 | Batch ID: 200 | Loss: 0.02921345643699169\n",
      "Eopch: 8 | Batch ID: 400 | Loss: 0.03334726020693779\n",
      "Eopch: 8 | Batch ID: 600 | Loss: 0.01882951892912388\n",
      "Eopch: 8 | Batch ID: 800 | Loss: 0.10320685803890228\n",
      "Eopch: 8 | Batch ID: 1000 | Loss: 0.03388475626707077\n",
      "Eopch: 8 | Batch ID: 1200 | Loss: 0.06178608536720276\n",
      "Eopch: 8 | Batch ID: 1400 | Loss: 0.07517086714506149\n",
      "Eopch: 8 | Batch ID: 1600 | Loss: 0.048626165837049484\n",
      "Eopch: 8 | Batch ID: 1800 | Loss: 0.0023195003159344196\n",
      "Eopch: 8 | Batch ID: 2000 | Loss: 0.07273555546998978\n",
      "Eopch: 8 | Batch ID: 2200 | Loss: 0.2226940542459488\n",
      "\n",
      "Eopch: 9 | Batch ID: 0 | Loss: 0.29960960149765015\n",
      "Eopch: 9 | Batch ID: 200 | Loss: 0.045252349227666855\n",
      "Eopch: 9 | Batch ID: 400 | Loss: 0.01846448890864849\n",
      "Eopch: 9 | Batch ID: 600 | Loss: 0.02932863123714924\n",
      "Eopch: 9 | Batch ID: 800 | Loss: 0.14598529040813446\n",
      "Eopch: 9 | Batch ID: 1000 | Loss: 0.08329839259386063\n",
      "Eopch: 9 | Batch ID: 1200 | Loss: 0.03459315374493599\n",
      "Eopch: 9 | Batch ID: 1400 | Loss: 0.10553765296936035\n",
      "Eopch: 9 | Batch ID: 1600 | Loss: 0.02950747311115265\n",
      "Eopch: 9 | Batch ID: 1800 | Loss: 0.01475174818187952\n",
      "Eopch: 9 | Batch ID: 2000 | Loss: 0.7060610055923462\n",
      "Eopch: 9 | Batch ID: 2200 | Loss: 0.9049019813537598\n",
      "\n",
      "Eopch: 10 | Batch ID: 0 | Loss: 0.10246828943490982\n",
      "Eopch: 10 | Batch ID: 200 | Loss: 0.029649971053004265\n",
      "Eopch: 10 | Batch ID: 400 | Loss: 0.009724943898618221\n",
      "Eopch: 10 | Batch ID: 600 | Loss: 0.04332638904452324\n",
      "Eopch: 10 | Batch ID: 800 | Loss: 0.009900464676320553\n",
      "Eopch: 10 | Batch ID: 1000 | Loss: 0.08240657299757004\n",
      "Eopch: 10 | Batch ID: 1200 | Loss: 0.052457574754953384\n",
      "Eopch: 10 | Batch ID: 1400 | Loss: 0.012899073772132397\n",
      "Eopch: 10 | Batch ID: 1600 | Loss: 0.005988351535052061\n",
      "Eopch: 10 | Batch ID: 1800 | Loss: 0.056754983961582184\n",
      "Eopch: 10 | Batch ID: 2000 | Loss: 0.17052064836025238\n",
      "Eopch: 10 | Batch ID: 2200 | Loss: 0.11134757101535797\n",
      "\n",
      "Eopch: 11 | Batch ID: 0 | Loss: 0.004839781671762466\n",
      "Eopch: 11 | Batch ID: 200 | Loss: 0.003930811304599047\n",
      "Eopch: 11 | Batch ID: 400 | Loss: 0.16326697170734406\n",
      "Eopch: 11 | Batch ID: 600 | Loss: 0.05499214306473732\n",
      "Eopch: 11 | Batch ID: 800 | Loss: 0.019029509276151657\n",
      "Eopch: 11 | Batch ID: 1000 | Loss: 0.08184129744768143\n",
      "Eopch: 11 | Batch ID: 1200 | Loss: 0.004919253755360842\n",
      "Eopch: 11 | Batch ID: 1400 | Loss: 0.037705935537815094\n",
      "Eopch: 11 | Batch ID: 1600 | Loss: 0.05804968252778053\n",
      "Eopch: 11 | Batch ID: 1800 | Loss: 0.0035389382392168045\n",
      "Eopch: 11 | Batch ID: 2000 | Loss: 0.028357049450278282\n",
      "Eopch: 11 | Batch ID: 2200 | Loss: 0.04429245740175247\n",
      "\n",
      "Eopch: 12 | Batch ID: 0 | Loss: 0.1131310909986496\n",
      "Eopch: 12 | Batch ID: 200 | Loss: 0.05558031052350998\n",
      "Eopch: 12 | Batch ID: 400 | Loss: 0.005962379276752472\n",
      "Eopch: 12 | Batch ID: 600 | Loss: 0.03744511678814888\n",
      "Eopch: 12 | Batch ID: 800 | Loss: 0.07910975068807602\n",
      "Eopch: 12 | Batch ID: 1000 | Loss: 0.09161955863237381\n",
      "Eopch: 12 | Batch ID: 1200 | Loss: 0.0028642842080444098\n",
      "Eopch: 12 | Batch ID: 1400 | Loss: 0.23614081740379333\n",
      "Eopch: 12 | Batch ID: 1600 | Loss: 0.007087374571710825\n",
      "Eopch: 12 | Batch ID: 1800 | Loss: 0.004734992515295744\n",
      "Eopch: 12 | Batch ID: 2000 | Loss: 0.037745796144008636\n",
      "Eopch: 12 | Batch ID: 2200 | Loss: 0.18579913675785065\n",
      "\n",
      "Eopch: 13 | Batch ID: 0 | Loss: 0.4066142439842224\n",
      "Eopch: 13 | Batch ID: 200 | Loss: 0.06085624545812607\n",
      "Eopch: 13 | Batch ID: 400 | Loss: 0.04121455177664757\n",
      "Eopch: 13 | Batch ID: 600 | Loss: 0.032818008214235306\n",
      "Eopch: 13 | Batch ID: 800 | Loss: 0.01614668034017086\n",
      "Eopch: 13 | Batch ID: 1000 | Loss: 0.0753822773694992\n",
      "Eopch: 13 | Batch ID: 1200 | Loss: 0.0053423200733959675\n",
      "Eopch: 13 | Batch ID: 1400 | Loss: 0.051761068403720856\n",
      "Eopch: 13 | Batch ID: 1600 | Loss: 0.00048301214701496065\n",
      "Eopch: 13 | Batch ID: 1800 | Loss: 0.00022168336727190763\n",
      "Eopch: 13 | Batch ID: 2000 | Loss: 0.16453507542610168\n",
      "Eopch: 13 | Batch ID: 2200 | Loss: 0.1286323368549347\n",
      "\n",
      "Eopch: 14 | Batch ID: 0 | Loss: 0.9780858159065247\n",
      "Eopch: 14 | Batch ID: 200 | Loss: 0.09119924157857895\n",
      "Eopch: 14 | Batch ID: 400 | Loss: 0.011569998227059841\n",
      "Eopch: 14 | Batch ID: 600 | Loss: 0.005944013595581055\n",
      "Eopch: 14 | Batch ID: 800 | Loss: 0.03985581174492836\n",
      "Eopch: 14 | Batch ID: 1000 | Loss: 0.004283620975911617\n",
      "Eopch: 14 | Batch ID: 1200 | Loss: 0.00233447109349072\n",
      "Eopch: 14 | Batch ID: 1400 | Loss: 0.0013643540441989899\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(pre_model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(pre_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    for i, (labels, images) in enumerate(train_dataset_loader):\n",
    "        images = Variable(images).cuda()\n",
    "        labels = Variable(labels).cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = pre_model(images.float())\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%200 == 0:\n",
    "            print(f\"Eopch: {epoch} | Batch ID: {i} | Loss: {loss.data}\")\n",
    "    print()\n",
    "\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2c02d4-f4ac-493c-9011-a3ff4ce5c6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = []\n",
    "all_predictions = []\n",
    "\n",
    "for labels, images in valid_dataset_loader:\n",
    "    with torch.no_grad():\n",
    "        images = Variable(images).cuda()\n",
    "        labels = Variable(labels).cuda()\n",
    "        \n",
    "        pred = pre_model(images.float())\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        \n",
    "        targets.extend(labels.cpu().numpy())\n",
    "        \n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "\n",
    "        \n",
    "accuracy_val = accuracy_score(targets, all_predictions)\n",
    "f1_score_val = np.mean(f1_score(targets, all_predictions, average=None))\n",
    "print(f\"Accuracy: {accuracy_val}\")\n",
    "print(f\"F1 Score: {f1_score_val}\")\n",
    "\n",
    "wandb.log({'accuracy': accuracy_val, \n",
    "           'f1_score': f1_score_val,\n",
    "           'BATCH_SIZE': BATCH_SIZE,\n",
    "           'NUM_EPOCH': NUM_EPOCH,\n",
    "           'LEARNING_RATE': LEARNING_RATE,\n",
    "           'SEED': SEED,\n",
    "           'TEST_SIZE':TEST_SIZE})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a144d6-bdf9-48fb-9e4d-d95e2b12702c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
