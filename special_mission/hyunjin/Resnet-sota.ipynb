{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b17a4fc",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dfb91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import math\n",
    "\n",
    "import os, sys\n",
    "import skimage.io\n",
    "from skimage.transform import resize\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "from tqdm import tqdm\n",
    "import PIL\n",
    "from PIL import Image, ImageOps\n",
    "import cv2\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from sklearn.metrics import f1_score, fbeta_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "WORKERS = 2\n",
    "CHANNEL = 3\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "IMG_SIZE = 512\n",
    "NUM_CLASSES = 18\n",
    "SEED = 42\n",
    "TRAIN_NUM = 1000 # use 1000 when you just want to explore new idea, use -1 for full train\n",
    "\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304e3e85",
   "metadata": {},
   "source": [
    "# Data Preprocessing & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a731ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/opt/ml/input/data/level1-image-classification-level1-nlp-6/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8e61aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d7e289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출처: https://github.com/utkuozbulak/pytorch-custom-dataset-examples/blob/master/src/custom_dataset_from_file.py\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "from torchvision import transforms\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset  # For custom datasets\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "\n",
    "\n",
    "transform = transforms.Compose([Resize((512, 384), Image.BILINEAR),\n",
    "                                ToTensor(),\n",
    "                                Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2))])\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df_train, transform, train=True):\n",
    "        # Get image list\n",
    "        self.image_list = df_train['path'].tolist()\n",
    "        self.target = df_train['class'].tolist()\n",
    "        # Calculate len\n",
    "        self.data_len = len(self.image_list)\n",
    "\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get image name from the pandas df\n",
    "        single_image_path = self.image_list[index]\n",
    "        # Open image\n",
    "        # Open image\n",
    "        image = Image.open(single_image_path)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(image)\n",
    "    \n",
    "        if self.train:\n",
    "            label = self.target[index]\n",
    "            \n",
    "            return (img, torch.tensor(label))\n",
    "        else:\n",
    "            return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cb2be9",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c097f780",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MyCustomModel, self).__init__()\n",
    "        \n",
    "        self.efficientnet_b7 = models.efficientnet_b7(pretrained=True)\n",
    "        self.efficientnet_b7.fc = torch.nn.Linear(in_features=512, out_features=18, bias=True)\n",
    "        \n",
    "        # initialize\n",
    "        nn.init.xavier_uniform_(self.efficientnet_b7.fc.weight)\n",
    "        stdv = 1. / math.sqrt(self.efficientnet_b7.fc.weight.size(1))\n",
    "        self.efficientnet_b7.fc.bias.data.uniform_(-stdv,stdv)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.efficientnet(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c331c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "   \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=0, alpha=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n",
    "        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        if input.dim()>2:\n",
    "            input = input.view(input.size(0),input.size(1),-1)  # N,C,H,W => N,C,H*W\n",
    "            input = input.transpose(1,2)    # N,C,H*W => N,H*W,C\n",
    "            input = input.contiguous().view(-1,input.size(2))   # N,H*W,C => N*H*W,C\n",
    "        target = target.view(-1,1)\n",
    "\n",
    "        logpt = F.log_softmax(input)\n",
    "        logpt = logpt.gather(1,target)\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = Variable(logpt.data.exp())\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type()!=input.data.type():\n",
    "                self.alpha = self.alpha.type_as(input.data)\n",
    "            at = self.alpha.gather(0,target.data.view(-1))\n",
    "            logpt = logpt * Variable(at)\n",
    "\n",
    "        loss = -1 * (1-pt)**self.gamma * logpt\n",
    "        if self.size_average: return loss.mean()\n",
    "        else: return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be9bcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "   \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.dataset import Dataset  # For custom datasets\n",
    "\n",
    "report_every = 100\n",
    "\n",
    "def eval(model,data_iter,criterion,epoch):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    batch_num = 0\n",
    "    \n",
    "    for i, (images, labels) in enumerate(data_iter):\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        total_loss += loss.data\n",
    "        batch_num += 1\n",
    "        \n",
    "    loss = total_loss / batch_num\n",
    "    model.train()\n",
    "    \n",
    "    return loss\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Dataset variant 3:\n",
    "    # Read images from a folder, image classes are embedded in file names\n",
    "    # No csv is used whatsoever\n",
    "    # No torch transformations are used\n",
    "    # Preprocessing operations are defined inside the dataset\n",
    "    train_dataset = CustomDataset(train_df, transform = transform)\n",
    "    valid_dataset = CustomDataset(valid_df, transform = transform)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                                    batch_size=8,\n",
    "                                                    shuffle=True)\n",
    "    valid_dataloader = torch.utils.data.DataLoader(dataset=valid_dataset,\n",
    "                                                    batch_size=8,\n",
    "                                                    shuffle=True)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    model = MyCustomModel()\n",
    "    model = model.to(device)\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    running_loss = 0\n",
    "    min_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(100): \n",
    "        for i, (images, labels) in enumerate(train_dataloader):\n",
    "            images = Variable(images).to(device)\n",
    "            labels = Variable(labels).to(device)\n",
    "            \n",
    "            # Clear gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            # Update weights\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            if i % report_every == 0:\n",
    "                eval_loss = eval(model, valid_dataloader, criterion, epoch)\n",
    "                if eval_loss < min_loss:\n",
    "                    min_loss = eval_loss\n",
    "                    torch.save(model, \"./model/epoch_%d_loss_%6f.pt\" % (epoch, min_loss))\n",
    "                print('Epoch: %d - Batch ID:%d - Min Loss:%f - Cur Loss:%f' %(epoch, i, min_loss, loss))\n",
    "            \n",
    "\n",
    "    print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cc0b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 state_dict 출력\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "  \n",
    "torch.save(model, \"./model/jj+bce.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1fde02",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e09246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"./model/epoch_6_loss_0.923871.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c879a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(test_df, transform)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                            batch_size=8,\n",
    "                                            shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea463a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = []\n",
    "all_predictions = []\n",
    "for images, labels in test_dataloader:\n",
    "    with torch.no_grad():\n",
    "        #images = images.to(device)\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        targets.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a846683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "print('accuracy', metrics.accuracy_score(targets, all_predictions) )\n",
    "print('f1', np.mean(metrics.f1_score(targets, all_predictions, average=None)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f7b062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a33fd88",
   "metadata": {},
   "source": [
    "# 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cc4173",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/opt/ml/input/data/train/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6356209",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['age_class'] = 0\n",
    "\n",
    "# 30 미만: 0 / 30 ~ 60: 1 / 60 이상: 2\n",
    "df_train.loc[df_train['age'] < 30, 'age_class'] = 0\n",
    "df_train.loc[(df_train['age'] < 60) & (df_train['age'] >= 30), 'age_class'] = 1\n",
    "df_train.loc[df_train['age'] >= 60, 'age_class'] = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d705345f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(['race'], axis=1)\n",
    "df_train = df_train.drop(['age'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c2046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sort_values(by=['gender', 'age_class'])\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_train['index'] = df_train.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb86f3c9",
   "metadata": {},
   "source": [
    "* 여성 0 ~ 1657\n",
    "    * under 30: 0 ~ 731\n",
    "        * train: 0 ~ 438\n",
    "        * valid: 439 ~ 585\n",
    "        * test: 586 ~ 731\n",
    "    * 30 to 60: 732 ~ 1548\n",
    "        * train: 732 ~ 1221\n",
    "        * valid: 1222 ~ 1384\n",
    "        * test: 1385 ~ 1548\n",
    "    * over 60: 1549 ~ 1657\n",
    "        * train: 1549 ~ 1613\n",
    "        * valid: 1614 ~ 1635\n",
    "        * test: 1636 ~ 1657\n",
    "* 남성 1658 ~ 2699\n",
    "    * under 30: 1658 ~ 2206\n",
    "        * train: 1658 ~ 1986\n",
    "        * valid: 1987 ~ 2097\n",
    "        * test: 2098 ~ 2206\n",
    "    * 30 to 60: 2207 ~ 2616\n",
    "        * train: 2207 ~ 2452\n",
    "        * valid: 2453 ~ 2534\n",
    "        * test: 2535 ~ 2616\n",
    "    * over 60: 2617 ~ 2699\n",
    "        * train: 2617 ~ 2666\n",
    "        * valid: 2667 ~ 2682\n",
    "        * test: 2683 ~ 2699\n",
    "\n",
    "* train 60% / valid 20% / test 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c641eeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([df_train[0:438], df_train[732:1221], df_train[1549:1613], df_train[1658:1986], df_train[2207:2452], df_train[2617:2666]])\n",
    "valid_df = pd.concat([df_train[429:585], df_train[1222:1384], df_train[1614:1635], df_train[1987:2097], df_train[2453:2534], df_train[2667:2682]])\n",
    "test_df = pd.concat([df_train[586:731], df_train[1385:1548], df_train[1636:1657], df_train[2098:2206], df_train[2535:2616], df_train[2683:2699]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c75812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f65144",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_class = pd.DataFrame(columns = ['per_id', 'class', 'path'])\n",
    "#df_train_class.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db174bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_class_simple(row, mask):\n",
    "    # Assuming the mask is already labeled as 0,1,2\n",
    "    # Each of them is 'wear', 'incorrect' and 'not wear'\n",
    "    gender = 0 if row[\"gender\"] == \"male\" else 3\n",
    "    age = row[\"age_class\"]\n",
    "\n",
    "    # Print the class number\n",
    "    return mask*6 + gender + age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7bcb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../input/data/train/images'\n",
    "idx = 0\n",
    "mask_dict = {0: 'wear', 1: 'not wear', 2: 'incorrect'}\n",
    "age_dict = {0: 'under 30', 1: '30 to 60', 2: 'over 60'}\n",
    "\n",
    "for i in train_df.index:\n",
    "    row = train_df.loc[i]\n",
    "\n",
    "    \n",
    "    imgs_path = os.path.join(path, row['path'])\n",
    "    images = sorted([f for f in os.listdir(imgs_path) if \"._\" not in f])\n",
    "    for img in images:\n",
    "        if img[:-4] == 'incorrect_mask':\n",
    "            mask = 2 # incorrect\n",
    "        elif img[:-4] == 'normal':\n",
    "            mask = 1 # not wear\n",
    "        else:\n",
    "            mask = 0 # wear\n",
    "\n",
    "        classnum = return_class_simple(row, mask)\n",
    "        \n",
    "\n",
    "        df_train_class.loc[idx] = [row['id'], classnum, os.path.join(imgs_path, img)]\n",
    "        idx += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe18c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_class = pd.DataFrame(columns = ['per_id', 'class', 'path'])\n",
    "#df_train_class.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d67bf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../input/data/train/images'\n",
    "idx = 0\n",
    "mask_dict = {0: 'wear', 1: 'not wear', 2: 'incorrect'}\n",
    "age_dict = {0: 'under 30', 1: '30 to 60', 2: 'over 60'}\n",
    "\n",
    "for i in valid_df.index:\n",
    "    row = valid_df.loc[i]\n",
    "\n",
    "    \n",
    "    imgs_path = os.path.join(path, row['path'])\n",
    "    images = sorted([f for f in os.listdir(imgs_path) if \"._\" not in f])\n",
    "    for img in images:\n",
    "        if img[:-4] == 'incorrect_mask':\n",
    "            mask = 2 # incorrect\n",
    "        elif img[:-4] == 'normal':\n",
    "            mask = 1 # not wear\n",
    "        else:\n",
    "            mask = 0 # wear\n",
    "\n",
    "        classnum = return_class_simple(row, mask)\n",
    "        \n",
    "\n",
    "        df_valid_class.loc[idx] = [row['id'], classnum, os.path.join(imgs_path, img)]\n",
    "        idx += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44010654",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_class = pd.DataFrame(columns = ['per_id', 'class', 'path'])\n",
    "#df_train_class.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd2bd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../input/data/train/images'\n",
    "idx = 0\n",
    "mask_dict = {0: 'wear', 1: 'not wear', 2: 'incorrect'}\n",
    "age_dict = {0: 'under 30', 1: '30 to 60', 2: 'over 60'}\n",
    "\n",
    "for i in test_df.index:\n",
    "    row = test_df.loc[i]\n",
    "\n",
    "    \n",
    "    imgs_path = os.path.join(path, row['path'])\n",
    "    images = sorted([f for f in os.listdir(imgs_path) if \"._\" not in f])\n",
    "    for img in images:\n",
    "        if img[:-4] == 'incorrect_mask':\n",
    "            mask = 2 # incorrect\n",
    "        elif img[:-4] == 'normal':\n",
    "            mask = 1 # not wear\n",
    "        else:\n",
    "            mask = 0 # wear\n",
    "\n",
    "        classnum = return_class_simple(row, mask)\n",
    "        \n",
    "\n",
    "        df_test_class.loc[idx] = [row['id'], classnum, os.path.join(imgs_path, img)]\n",
    "        idx += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2a5c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_class.to_csv(\"./train.csv\")\n",
    "df_valid_class.to_csv(\"./valid.csv\")\n",
    "df_test_class.to_csv(\"./test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2d5d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
